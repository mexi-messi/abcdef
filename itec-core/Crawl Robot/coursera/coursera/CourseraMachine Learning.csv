weekabout,targetlearner,description,language,creator,coursename,imageurl,instructors,weekgraded,url,ratingcount,ratingstars,basicinfo,weekinfo,weekname
"(['Welcome to first week of our course! Today we will discuss what bayesian methods are and what are probabilistic models. We will see how they can be used to model real-life situations and how to make conclusions from them. We will also learn about conjugate priors \xe2\x80\x94 a class of models where all math becomes really simple.', 'This week we will about the central topic in probabilistic modeling: the Latent Variable Models and how to train them, namely the Expectation Maximization algorithm. We will see models for clustering and dimensionality reduction where Expectation Maximization algorithm can be applied as is. In the following weeks, we will spend weeks 3, 4, and 5 discussing numerous extensions to this algorithm to make it work for more complicated models and scale to large datasets.', 'This week we will move on to approximate inference methods. We will see why we care about approximating distributions and see variational inference \xe2\x80\x94 one of the most powerful methods for this task. We will also see mean-field approximation in details. And apply it to text-mining algorithm called Latent Dirichlet Allocation', 'This week we will learn how to approximate training and inference with sampling and how to sample from complicated distributions. This will allow us to build simple method to deal with LDA and with Bayesian Neural Networks \xe2\x80\x94 Neural Networks which weights are random variables themselves and instead of training (finding the best value for the weights) we will sample from the posterior distributions on weights.', 'Welcome to the fifth week of the course! This week we will combine many ideas from the previous weeks and add some new to build Variational Autoencoder -- a model that can learn a distribution over structured data (like photographs or molecules) and then sample new data points from the learned distribution, hallucinating new photographs of non-existing people. We will also the same techniques to Bayesian Neural Networks and will see how this can greatly compress the weights of the network without reducing the accuracy.', 'Welcome to the final week of our course! This time we will see nonparametric Bayesian methods. Specifically, we will learn about Gaussian processes and their application to Bayesian optimization that allows one to perform optimization for scenarios in which each function evaluation is very expensive: oil probe, drug discovery and neural network architecture tuning.'],)","(['This course was designed for students with strong mathematical and machine learning background who want to get a different perspective of ML algorithms.\nNote that this is a very advanced course! You must have strong background in statistics, calculus and linear algebra.'],)","(['Bayesian methods are used in lots of fields: from game development to drug discovery. They give superpowers to many machine learning algorithms: handling missing data, extracting  much more information from small datasets. Bayesian methods also allow us to estimate uncertainty in predictions, which is a really desirable feature for fields like medicine. \nWhen Bayesian methods are applied to deep learning, it turns out that they allow you to compress your models 100 folds, and automatically tune hyperparametrs, saving your time and money.\nIn six weeks we will discuss the basics of Bayesian methods: from how to define a probabilistic model to how to make predictions from it. We will see how one can fully automate this workflow and how to speed it up using some advanced techniques. \nWe will also see applications of Bayesian methods to deep learning and how to generate new images with it. We will see how new drugs that cure severe diseases be found with Bayesian methods.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Bayesian Methods for Machine Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/2a/d9b6308bd711e798da81f093f62c3a/Bayesian-machine-learning.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Daniil Polykovskiy', 'Alexander Novikov'],)","(['Introduction to Bayesian methods', 'Conjugate priors', 'EM algorithm', 'Latent Variable Models and EM algorithm', 'EM algorithm for GMM', 'Variational inference', 'Latent Dirichlet Allocation', 'Markov Chain Monte Carlo', 'PyMC', 'Variational autoencoders', 'Variational Autoencoder', 'Categorical Reparametrization with Gumbel-Softmax', 'Gaussian Processes and Bayesian Optimization', 'GPy and GPyOpt', 'Final project: Finding the suspect'],)",https://www.coursera.org/learn/bayesian-methods-in-machine-learning,34,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Advanced', '6 weeks of study, 6 hours/week', 'Access to GPUs will be a plus, but you can complete the course without them.', 'Pass all graded assignments to complete the course.'],)","(['9 videos', ', ', '1 reading', '17 videos', '11 videos', '11 videos', '10 videos', ', ', '3 readings', '7 videos'],)","(['Introduction to Bayesian methods & Conjugate priors', 'Expectation-Maximization algorithm', 'Variational Inference & Latent Dirichlet Allocation', 'Markov chain Monte Carlo', 'Variational Autoencoder', 'Gaussian processes & Bayesian optimization', 'Final project'],)"
"([],)","(['Pre-requisites:\n- This course is aimed at individuals with basic knowledge of machine learning, who want to know how to set technical direction and prioritization for their work.\n- It is recommended that you take course one and two of this specialization (Neural Networks and Deep Learning, and Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization) prior to beginning this course.'],)","(['You will learn how to build a successful machine learning project. If you aspire to be a technical leader in AI, and know how to set direction for your team\'s work, this course will show you how.\n\nMuch of this content has never been taught elsewhere, and is drawn from my experience building and shipping many deep learning products. This course also has two ""flight simulators"" that let you practice decision-making as a machine learning project leader. This provides ""industry experience"" that you might otherwise get only after years of ML work experience.\n\nAfter 2 weeks, you will: \n- Understand how to diagnose errors in a machine learning system, and \n- Be able to prioritize the most promising directions for reducing error\n- Understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance\n- Know how to apply end-to-end learning, transfer learning, and multi-task learning\n\nI\'ve seen teams waste months or years through not understanding the principles taught in this course. I hope this two week course will save you months of time.\n\nThis is a standalone course, and you can take this so long as you have basic machine learning knowledge. This is the third course in the Deep Learning Specialization.'],)","(['English'],)","(['deeplearning.ai'],)","(['Structuring Machine Learning Projects'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/f1/e756d078c511e79def7f8c8906ac6e/CourseHeaderDL.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Andrew Ng', 'Head Teaching Assistant - Kian Katanforoosh', 'Teaching Assistant - Younes Bensouda Mourri'],)","(['Bird recognition in the city of Peacetopia (case study)', 'Autonomous driving (case study)'],)",https://www.coursera.org/learn/machine-learning-projects,"7,915","(['Rated 4.8 out of 5 of ', ' ratings'],)","(['Beginner', '2 weeks of study, 3-4 hours/week', ""None currently, unless you'd like to download Jupyter Notebooks locally for offline work."", 'Pass all graded assignments to complete the course.'],)","(['13 videos', ', ', '1 reading', '11 videos'],)","(['ML Strategy (1)', 'ML Strategy (2)'],)"
"(['In this week, we will first provide an overview on the course\'s content, targeted audiences, the instructor\'s professional background, and tips to succeed in this course. Then we will cover critical material properties in design, such as strength, modulus of elasticity, and the coefficient of thermal expansion. A case study examining material selection in a Zimmer orthopedic hip implant will demonstrate the real life design applications of these material properties. At the end of the week you will have the opportunity to check your own knowledge of these fundamental material properties by taking Quiz 1 ""Material Properties in Design.""', 'In week 2, we will review stress, strength, and the factory of safety. Specifically, we will review axial, torsional, bending, and transverse shear stresses. Please note that these modules are intended for review- students should already be familiar with these topics from their previous solid mechanics, mechanics of materials, or deformable bodies course. For each topic this week, be sure to refresh your analysis skills by working through worksheets 2, 3, 4 and 5. There is no quiz for this week.', 'In this week we will first cover the ductile to brittle transition temperature and stress concentration factors. Then, we will learn two critical static failure theories; the Distortion Energy Theory and Brittle Coulomb-Mohr Theory. A case study featuring the ultimate load testing of the Boeing 777 will highlight the importance of analysis and validation. Be sure to work through worksheets 6, 7, 8 and 9 to self-check your understanding of the course materials. At the end of this week, you will take Quiz 2 \xe2\x80\x9cStatic Failure.\xe2\x80\x9d', 'In week 4, we will introduce critical fatigue principles, starting with fully revisable stresses and the SN Curve. Then, we discuss how to estimate a fully adjusted endurance limit. Finally, a case study covering the root cause analysis of the fatigue failure of the Aloha Airlines flight 293 will emphasize the dangers of fatigue failure.  In this week, you should complete worksheets 10, 11 and 12 as well as Quiz 3 \xe2\x80\x9cFully Reversed Loading in Fatigue.\xe2\x80\x9d', 'In this last week of the course, we will cover the fatigue failure criteria for fluctuating and randomly varying stresses, including key concepts such as the Modified Goodman line and Miner s Rule. This week be sure to complete worksheets 13 and 14 as well as Quiz 4 \xe2\x80\x9cFluctuating Fatigue and Miner s Rule.\xe2\x80\x9d Finally, take Quiz 5, \xe2\x80\x9cThe Comprehensive Quiz\xe2\x80\x9d, which will measure your overall knowledge of this course.'],)","(['This course is aimed at undergraduate students with an interest in machine design, as well as practicing engineers who want to want to enhance their mechanical design and analysis skills. If you are a practicing mechanical engineer who seeks to add to your knowledge of machine design, or an undergraduate student who wants additional learning opportunities out of your classroom, this course is for you.'],)","(['\xe2\x80\x9cMachine Design Part I\xe2\x80\x9d is the first course in an in-depth three course series of \xe2\x80\x9cMachine Design.\xe2\x80\x9d The \xe2\x80\x9cMachine Design\xe2\x80\x9d Coursera series covers fundamental mechanical design topics, such as static and fatigue failure theories, the analysis of shafts, fasteners, and gears, and the design of mechanical systems such as gearboxes. Throughout this series of courses we will examine a number of exciting design case studies, including the material selection of a total hip implant, the design and testing of the wing on the 777 aircraft, and the impact of dynamic loads on the design of an bolted pressure vessel. \n\nIn this first course, you will learn robust analysis techniques to predict and validate design performance and life. We will start by reviewing critical material properties in design, such as stress, strength, and the coefficient of thermal expansion. We then transition into static failure theories such as von Mises theory, which can be utilized to prevent failure in static loading applications such as the beams in bridges.  Finally, we will learn fatigue failure criteria for designs with dynamic loads, such as the input shaft in the transmission of a car.'],)","(['English'],)","(['Georgia Institute of Technology'],)","(['Machine Design Part I'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0f/b90b206eb511e6a1c0d77b7ec6029c/machine_design_coursera_icon.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Dr. Kathryn Wingate'],)","(['Material Properties in Design', 'Static Failure', 'Fully Reversed Loading in Fatigue', 'Fluctuating Fatigue and Miner\xe2\x80\x99s Rule', 'Machine Design Part 1: Comprehensive Exam'],)",https://www.coursera.org/learn/machine-design1,355,"(['Rated 4.8 out of 5 of ', ' ratings'],)","(['Intermediate', 'This class includes 5 weeks of study, 5-7 hours/week.', 'none', 'Pass all graded assignments to complete the course.'],)","(['11 videos', ', ', '4 readings', ', ', '1 practice quiz', '8 videos', ', ', '10 readings', ', ', '1 practice quiz', '9 videos', ', ', '12 readings', '8 videos', ', ', '10 readings', '8 videos', ', ', '10 readings'],)","(['Material Properties in Design', 'Static Failure Theories - Part I', 'Static Failure Theories - Part II', 'Fatigue Failure - Part I', 'Fatigue Failure - Part II'],)"
"([""This week we will introduce you to competitive data science. You will learn about competitions' mechanics, the difference between competitions and a real life data science,  hardware and software that people usually use in competitions. We will also briefly recap major ML models frequently used in competitions."", 'In this module we will summarize approaches to work with features: preprocessing, generation and extraction. We will see, that the choice of the machine learning model impacts both preprocessing we apply to the features and our approach to generation of new ones. We will also discuss feature extraction from text with Bag Of Words and Word2vec, and feature extraction from images with Convolution Neural Networks.', 'We will start this week with Exploratory Data Analysis (EDA). It is a very broad and exciting topic and an essential component of solving process. Besides regular videos you will find a walk through EDA process for Springleaf competition data and an example of prolific EDA for NumerAI competition with extraordinary findings.', 'Finally, in this module we will cover something very unique to data science competitions. That is, we will see examples how it is sometimes possible to get a top position in a competition with a very little machine learning, just by exploiting a data leakage.   ', 'Nowadays it is hard to find a competition won by a single model! Every winning solution incorporates ensembles of models. In this module we will talk about the main ensembling techniques in general, and, of course, how it is better to ensemble the models in practice. '],)","([],)","(['If you want to break into competitive data science, then this course is for you! Participating in predictive modelling competitions can help you gain practical experience, improve and harness your data modelling skills in various domains such as credit, insurance, marketing, natural language processing, sales\xe2\x80\x99 forecasting and computer vision to name a few. At the same time you get to do it in a competitive context against thousands of participants where each one tries to build the most predictive algorithm. Pushing each other to the limit can result in better performance and smaller prediction errors. Being able to achieve high ranks consistently can help you accelerate your career in data science.\n\nIn this course, you will learn to analyse and solve competitively such predictive modelling tasks. \n\nWhen you finish this class, you will:\n\n- Understand how to solve predictive modelling competitions efficiently and learn which of the skills obtained can be applicable to real-world tasks.\n- Learn how to preprocess the data and generate new features from various sources such as text and images.\n- Be taught advanced feature engineering techniques like generating mean-encodings, using aggregated statistical measures or finding nearest neighbors as a means to improve your predictions.\n- Be able to form reliable cross validation methodologies that help you benchmark your solutions and avoid overfitting or underfitting when tested with unobserved (test) data. \n- Gain experience of analysing and interpreting the data. You will become aware of inconsistencies, high noise levels, errors and other data-related issues such as leakages and you will learn how to overcome them. \n- Acquire knowledge of different algorithms and learn how to efficiently tune their hyperparameters and achieve top performance. \n- Master the art of combining different machine learning models and learn how to ensemble. \n- Get exposed to past (winning) solutions and codes and learn how to read them.\n\nDisclaimer : This is not a machine learning course in the general sense. This course will teach you how to get high-rank solutions against thousands of competitors with focus on practical usage of machine learning methods rather than the theoretical underpinnings behind them.\n\nPrerequisites: \n- Python: work with DataFrames in pandas, plot figures in matplotlib, import and train models from scikit-learn, XGBoost, LightGBM.\n- Machine Learning: basic understanding of linear models, K-NN, random forest, gradient boosting and neural networks.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['How to Win a Data Science Competition: Learn from Top Kagglers'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/79/35e6f08e6b11e786129d44e814c9e9/How-to-win-a-Kaggle-competition.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Dmitry Ulyanov', 'Alexander Guschin', 'Mikhail Trofimov', 'Dmitry Altukhov', 'Marios Michailidis'],)","(['Recap', 'Pandas basics', 'Graded Soft/Hard Quiz', 'Feature preprocessing and generation with respect to models', 'Feature extraction from text and images', 'Exploratory data analysis', 'Validation', 'Data leakages', 'Data leakages', 'Data leakages', 'Metrics', 'Mean encodings', 'Mean encoding implementation', 'Graded quiz', 'Graded Advanced Features II Quiz', 'KNN features implementation', 'Ensembling implementation', 'Ensembling', 'Final project', 'Final project'],)",https://www.coursera.org/learn/competitive-data-science,58,"(['Rated 4.8 out of 5 of ', ' ratings'],)","(['Advanced', '6-10 hours/week', 'Pass all graded assignments to complete the course.'],)","(['8 videos', ', ', '7 readings', ', ', '3 practice quizzes', '7 videos', ', ', '4 readings', ', ', '2 practice quizzes', '1 video', ', ', '2 readings', '8 videos', ', ', '2 readings', '4 videos', ', ', '3 readings', ', ', '1 practice quiz', '3 videos', ', ', '3 readings', '8 videos', ', ', '3 readings', ', ', '1 practice quiz', '3 videos', ', ', '2 readings', '4 videos', ', ', '4 readings', ', ', '1 practice quiz', '4 videos', ', ', '2 readings', '6 videos', ', ', '4 readings', ', ', '1 practice quiz', '4 videos', ', ', '2 readings'],)","(['Introduction & Recap', 'Feature Preprocessing and Generation with Respect to Models', 'Final Project Description', 'Exploratory Data Analysis', 'Validation', 'Data Leakages', 'Metrics Optimization', 'Advanced Feature Engineering I', 'Hyperparameter Optimization', 'Advanced feature engineering II', 'Ensembling', 'Competitions go through', 'Final Project'],)"
"(['This module introduces the idea of computational thinking, and how big data can make simple problems quite challenging to solve. We use the example of calculating the median and mean stack of a set of radio astronomy images to illustrate some of the issues you encounter when working with large datasets. ', 'In this module we explore the idea of scaling your code. Some algorithms scale well as your dataset increases, but others become impossibly slow. We look at some of the reason for this, and use the example of cross-matching astronomical catalogues to demonstrate what kind of improvements you can make. ', 'Most large astronomy projects use databases to manage their data. In this module we introduce SQL - the language most commonly used to query databases. We use SQL to query the NASA Exoplanet database and investigate the habitability of planets in other solar systems.'],)","(['This course is aimed at science students with an interest in computational approaches to problem solving, people with an interest in astronomy who would like to learn current research methods, or people who would like to improve their programming by applying it to astronomy examples. '],)","(['Science is undergoing a data explosion, and astronomy is leading the way. Modern telescopes produce terabytes of data per observation, and the simulations required to model our observable Universe push supercomputers to their limits. To analyse this data scientists need to be able to think computationally to solve problems. In this course you will investigate the challenges of working with large datasets: how to implement algorithms that work; how to use databases to manage your data; and how to learn from your data with machine learning tools. The focus is on practical skills - all the activities will be done in Python 3, a modern programming language used throughout astronomy.\n\nRegardless of whether you\xe2\x80\x99re already a scientist, studying to become one, or just interested in how modern astronomy works \xe2\x80\x98under the bonnet\xe2\x80\x99, this course will help you explore astronomy: from planets, to pulsars to black holes.\n\nCourse outline:\nWeek 1: Thinking about data\n- Principles of computational thinking\n- Discovering pulsars in radio images\n\nWeek 2: Big data makes things slow\n- How to work out the time complexity of algorithms\n- Exploring the black holes at the centres of massive galaxies\n\nWeek 3: Querying data using SQL\n- How to use databases to analyse your data\n- Investigating exoplanets in other solar systems\n\nWeek 4: Managing your data\n- How to set up databases to manage your data\n- Exploring the lifecycle of stars in our Galaxy\n\nWeek 5: Learning from data: regression\n- Using machine learning tools to investigate your data\n- Calculating the redshifts of distant galaxies\n\nWeek 6: Learning from data: classification\n- Using machine learning tools to classify your data\n- Investigating different types of galaxies\n\nEach week will also have an interview with a data-driven astronomy expert.\n\nNote that some knowledge of Python is assumed, including variables, control structures, data structures, functions, and working with files.'],)","(['English'],)","(['The University of Sydney'],)","(['Data-driven Astronomy'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0f/79d550ed5311e68a91457769e062c8/banner4.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Tara Murphy', 'Simon Murphy'],)","(['Set up your online assessment', 'Pulsars: test your understanding', 'Calculating the mean stack', 'Supermassive black holes: test your understanding', 'A naive cross-matcher', 'Exoplanets - test your understanding', 'Writing your own SQL queries', 'Stars - test your understanding', 'Setting up your own database', 'Cosmological distances - test your understanding', 'Building a regression classifier', 'Galaxies - test your understanding', 'Exploring machine learning classification'],)",https://www.coursera.org/learn/data-driven-astronomy,136,"(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Intermediate', '6 weeks of study, 4-6 hours/week', ""You'll need to have a computer with internet access."", 'Pass all graded assignments to complete the course.'],)","(['8 videos', ', ', '1 reading', '7 videos', '7 videos', '6 videos', '7 videos', '7 videos', ', ', '1 reading'],)","(['Thinking about data', 'Big data makes things slow', 'Querying your data', 'Managing your data', 'Learning from data: regression', 'Learning from data: classification'],)"
"(['Clustering and retrieval are some of the most high-impact machine learning tools out there.  Retrieval is used in almost every applications and device we interact with, like in providing a set of products related to one a shopper is currently considering, or a list of people you might want to connect with on a social media platform.  Clustering can be used to aid retrieval, but is a more broadly useful tool for automatically discovering structure in data, like uncovering groups of similar patients.<p>This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.', 'We start the course by considering a retrieval task of fetching a document similar to one someone is currently reading.  We cast this problem as one of nearest neighbor search, which is a concept we have seen in the Foundations and Regression courses.  However, here, you will take a deep dive into two critical components of the algorithms: the data representation and metric for measuring similarity between pairs of datapoints.  You will examine the computational burden of the naive nearest neighbor search algorithm, and instead implement scalable alternatives using KD-trees for handling large datasets and locality sensitive hashing (LSH) for providing approximate nearest neighbors, even in high-dimensional spaces.  You will explore all of these ideas on a Wikipedia dataset, comparing and contrasting the impact of the various choices you can make on the nearest neighbor results produced.', 'In clustering, our goal is to group the datapoints in our dataset into disjoint sets.  Motivated by our document analysis case study, you will use clustering to discover thematic groups of articles by ""topic"".  These topics are not provided in this unsupervised learning task; rather, the idea is to output such cluster labels that can be post-facto associated with known topics like ""Science"", ""World News"", etc.  Even without such post-facto labels, you will examine how the clustering output can provide insights into the relationships between datapoints in the dataset.  The first clustering algorithm you will implement is k-means, which is the most widely used clustering algorithm out there.  To scale up k-means, you will learn about the general MapReduce framework for parallelizing and distributing computations, and then how the iterates of k-means can utilize this framework.  You will show that k-means can provide an interpretable grouping of Wikipedia articles when appropriately tuned.', 'In k-means, observations are each hard-assigned to a single cluster, and these assignments are based just on the cluster centers, rather than also incorporating shape information.  In our second module on clustering, you will perform probabilistic model-based clustering that provides (1) a more descriptive notion of a ""cluster"" and (2) accounts for uncertainty in assignments of datapoints to clusters via ""soft assignments"".  You will explore and implement a broadly useful algorithm called expectation maximization (EM) for inferring these soft assignments, as well as the model parameters.  To gain intuition, you will first consider a visually appealing image clustering task.  You will then cluster Wikipedia articles, handling the high-dimensionality of the tf-idf document representation considered.', 'The clustering model inherently assumes that data divide into disjoint sets, e.g., documents by topic.  But, often our data objects are better described via memberships in a collection of sets, e.g., multiple topics.  In our fourth module, you will explore latent Dirichlet allocation (LDA) as an example of such a mixed membership model particularly useful in document analysis.  You will interpret the output of LDA, and various ways the output can be utilized, like as a set of learned document features.  The mixed membership modeling ideas you learn about through LDA for document analysis carry over to many other interesting models and applications, like social network models where people have multiple affiliations.<p>Throughout this module, we introduce aspects of Bayesian modeling and a Bayesian inference algorithm called Gibbs sampling.  You will be able to implement a Gibbs sampler for LDA by the end of the module.', ""In the conclusion of the course, we will recap what we have covered.  This represents both techniques specific to clustering and retrieval, as well as foundational machine learning concepts that are more broadly useful.<p>We provide a quick tour into an alternative clustering approach called hierarchical clustering, which you will experiment with on the Wikipedia dataset.  Following this exploration, we discuss how clustering-type ideas can be applied in other areas like segmenting time series.  We then briefly outline some important clustering and retrieval ideas that we did not cover in this course.<p> We conclude with an overview of what's in store for you in the rest of the specialization.  ""],)","([],)","(['Case Studies: Finding Similar Documents\n\nA reader is interested in a specific news article and you want to find similar articles to recommend.  What is the right notion of similarity?  Moreover, what if there are millions of other documents?  Each time you want to a retrieve a new document, do you need to search through all other documents?  How do you group similar documents together?  How do you discover new, emerging topics that the documents cover?   \n\nIn this third case study, finding similar documents, you will examine similarity-based algorithms for retrieval.  In this course, you will also examine structured representations for describing the documents in the corpus, including clustering and mixed membership models, such as latent Dirichlet allocation (LDA).  You will implement expectation maximization (EM) to learn the document clusterings, and see how to scale the methods using MapReduce.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Create a document retrieval system using k-nearest neighbors.\n   -Identify various similarity metrics for text data.\n   -Reduce computations in k-nearest neighbor search by using KD-trees.\n   -Produce approximate nearest neighbors using locality sensitive hashing.\n   -Compare and contrast supervised and unsupervised learning tasks.\n   -Cluster documents by topic using k-means.\n   -Describe how to parallelize k-means using MapReduce.\n   -Examine probabilistic clustering approaches using mixtures models.\n   -Fit a mixture of Gaussian model using expectation maximization (EM).\n   -Perform mixed membership modeling using latent Dirichlet allocation (LDA).\n   -Describe the steps of a Gibbs sampler and how to use its output to draw inferences.\n   -Compare and contrast initialization techniques for non-convex optimization objectives.\n   -Implement these techniques in Python.'],)","(['English'],)","(['University of Washington'],)","(['Machine Learning: Clustering & Retrieval'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/80/907e004d0011e5aa3207874406679c/gears-818461_1280.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Emily Fox', 'Carlos Guestrin'],)","(['Representations and metrics', 'Choosing features and metrics for nearest neighbor search', 'KD-trees', 'Locality Sensitive Hashing', 'Implementing Locality Sensitive Hashing from scratch', 'k-means', 'Clustering text data with K-means', 'MapReduce for k-means', 'EM for Gaussian mixtures', 'Implementing EM for Gaussian mixtures', 'Clustering text data with Gaussian mixtures', 'Latent Dirichlet Allocation', 'Learning LDA model via Gibbs sampling', 'Modeling text topics with Latent Dirichlet Allocation', 'Modeling text data with a hierarchy of clusters'],)",https://www.coursera.org/learn/ml-clustering-and-retrieval,"1,111","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['6 weeks of study, 5-8 hours/week', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '3 readings', '22 videos', ', ', '4 readings', '13 videos', ', ', '2 readings', '15 videos', ', ', '4 readings', '12 videos', ', ', '2 readings', '12 videos', ', ', '2 readings'],)","(['Welcome', 'Nearest Neighbor Search', 'Clustering with k-means', 'Mixture Models', 'Mixed Membership Modeling via Latent Dirichlet Allocation', 'Hierarchical Clustering & Closing Remarks'],)"
"([],)","(['Prerequisites: \n\nExpected:\n- Programming: Basic Python programming skills, with the capability to work effectively with data structures.  \n\nRecommended:\n- Mathematics: Matrix vector operations and notation.\n- Machine Learning: Understanding how to frame a machine learning problem, including how data is represented will be beneficial. If you have taken my Machine Learning Course here, you have much more than the needed level of knowledge. '],)","(['If you want to break into cutting-edge AI, this course will help you do so. Deep learning engineers are highly sought after, and mastering deep learning will give you numerous new career opportunities. Deep learning is also a new ""superpower"" that will let you build AI systems that just weren\'t possible a few years ago. \n\nIn this course, you will learn the foundations of deep learning. When you finish this class, you will:\n- Understand the major technology trends driving Deep Learning\n- Be able to build, train and apply fully connected deep neural networks \n- Know how to implement efficient (vectorized) neural networks \n- Understand the key parameters in a neural network\'s architecture \n\nThis course also teaches you how Deep Learning actually works, rather than presenting only a cursory or surface-level description. So after completing it, you will be able to apply deep learning to a your own applications. If you are looking for a job in AI, after this course you will also be able to answer basic interview questions. \n\nThis is the first course of the Deep Learning Specialization.'],)","(['English'],)","(['deeplearning.ai'],)","(['Neural Networks and Deep Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/1c/d973d0789611e78164fd698eb0de28/Deep-learningheader.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Andrew Ng', 'Head Teaching Assistant - Kian Katanforoosh', 'Teaching Assistant - Younes Bensouda Mourri'],)","(['Introduction to deep learning', 'Neural Network Basics', 'Logistic Regression with a Neural Network mindset', 'Shallow Neural Networks', 'Planar data classification with a hidden layer', 'Key concepts on Deep Neural Networks', 'Building your deep neural network: Step by Step', 'Deep Neural Network Application'],)",https://www.coursera.org/learn/neural-networks-deep-learning,"16,795","(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Intermediate', '4 weeks of study, 3-6 hours a week', 'Pass all graded assignments to complete the course.'],)","(['7 videos', ', ', '2 readings', '19 videos', ', ', '2 readings', '12 videos', '8 videos'],)","(['Introduction to deep learning', 'Neural Networks Basics', 'Shallow neural networks', 'Deep Neural Networks'],)"
"([],)","([],)","([],)","([],)","([],)","([],)",,"([],)","([],)",https://www.coursera.org/specializations/deep-learning,,"([],)","([],)","([],)","([],)"
"([],)","(['This course is for those new to data science.  Completion of \xe2\x80\x9cBig Data Integration and Processing\xe2\x80\x9d is recommended.  No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments.  Refer to the specialization technical requirements for complete hardware and software specifications.'],)","(['Want to make sense of the volumes of data you have collected?  Need to incorporate data-driven decisions into your process?  This course provides an overview of machine learning techniques to explore, analyze, and leverage data.  You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems.\n\nAt the end of the course, you will be able to:\n\xe2\x80\xa2\tDesign an approach to leverage data using the steps in the machine learning process.\n\xe2\x80\xa2\tApply machine learning techniques to explore and prepare data for modeling.\n\xe2\x80\xa2\tIdentify the type of machine learning problem in order to apply the appropriate set of techniques.\n\xe2\x80\xa2\tConstruct models that learn from data using widely available open source tools.\n\xe2\x80\xa2\tAnalyze big data problems using scalable machine learning algorithms on Spark.'],)","(['English'],)","(['University of California, San Diego'],)","(['Machine Learning With Big Data'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/7d/5f9a504d0911e5aa3207874406679c/big-data-_2_.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Mai Nguyen', 'Ilkay Altintas'],)","(['Machine Learning Overview', 'Data Exploration', 'Data Exploration in KNIME and Spark Quiz', 'Data Preparation', 'Handling Missing Values in KNIME and Spark Quiz', 'Classification', 'Classification in KNIME and Spark Quiz', 'Model Evaluation', 'Model Evaluation in KNIME and Spark Quiz', 'Regression, Cluster Analysis, & Association Analysis', 'Cluster Analysis in Spark Quiz'],)",https://www.coursera.org/learn/big-data-machine-learning,573,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['5 Weeks, 3 - 5 hours per week', 'Pass all graded assignments to complete the course.'],)","(['2 videos', '7 videos', ', ', '7 readings', '6 videos', ', ', '5 readings', '8 videos', ', ', '4 readings', '8 videos', ', ', '7 readings', '7 videos', ', ', '7 readings', '8 videos', ', ', '6 readings'],)","(['Welcome', 'Introduction to Machine Learning with Big Data', 'Data Exploration', 'Data Preparation', 'Classification', 'Evaluation of Machine Learning Models', 'Regression, Cluster Analysis, and Association Analysis'],)"
"([],)","([],)","([""Learn about artificial neural networks and how they're being used for machine learning, as applied to speech and object recognition, image segmentation, modeling language and human motion, etc. We'll emphasize both the basic algorithms and the practical tricks needed to get them to work well.\n\nThis course contains the same content presented on Coursera beginning in 2013. It is not a continuation or update of the original course. It has been adapted for the new platform.\n\nPlease be advised that the course is suited for an intermediate level learner - comfortable with calculus and with experience programming (Python).""],)","(['English'],)","(['University of Toronto'],)","(['Neural Networks for Machine Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/neuralnets/large-icon.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Geoffrey Hinton'],)","(['Lecture 1 Quiz', 'Lecture 2 Quiz', 'Lecture 3 Quiz', 'Programming Assignment 1: The perceptron learning algorithm.', 'Lecture 4 Quiz', 'Lecture 5 Quiz', 'Programming Assignment 2: Learning Word Representations.', 'Lecture 6 Quiz', 'Lecture 7 Quiz', 'Lecture 8 Quiz', 'Lecture 9 Quiz', 'Programming assignment 3: Optimization and generalization', 'Lecture 10 Quiz', 'Lecture 11 Quiz', 'Lecture 12 Quiz', 'Programming Assignment 4: Restricted Boltzmann Machines', 'Lecture 13 Quiz', 'Lecture 14 Quiz', 'Lecture 15 Quiz', 'Final Exam'],)",https://www.coursera.org/learn/neural-networks,"2,092","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['5 videos', ', ', '8 readings', '5 videos', ', ', '1 reading', '5 videos', ', ', '2 readings', '5 videos', ', ', '1 reading', '4 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '3 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '3 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '3 videos'],)","(['Introduction ', 'The Perceptron learning procedure', 'The backpropagation learning proccedure', 'Learning feature vectors for words', 'Object recognition with neural nets', 'Optimization: How to make the learning go faster', 'Recurrent neural networks', 'More recurrent neural networks', 'Ways to make neural networks generalize better', 'Combining multiple neural networks to improve generalization', 'Hopfield nets and Boltzmann machines', 'Restricted Boltzmann machines (RBMs)', 'Stacking RBMs to make Deep Belief Nets', 'Deep neural nets with generative pre-training', 'Modeling hierarchical structure with neural nets', 'Recent applications of deep neural nets'],)"
"([],)","([],)","(['One of the most common tasks performed by data scientists and data analysts are prediction and machine learning. This course will cover the basic components of building and applying prediction functions with an emphasis on practical applications. The course will provide basic grounding in concepts such as training and tests sets, overfitting, and error rates. The course will also introduce a range of model based and algorithmic machine learning methods including regression, classification trees, Naive Bayes, and random forests. The course will cover the complete process of building prediction functions including data collection, feature creation, algorithms, and evaluation.'],)","(['English'],)","(['Johns Hopkins University'],)","(['Practical Machine Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/a1/e7472069b611e3ae92c39913bb30e0/PredictionMachineLearning.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Jeff Leek, PhD', 'Roger D. Peng, PhD', 'Brian Caffo, PhD'],)","(['Quiz 1', 'Quiz 2', 'Quiz 3', 'Quiz 4', 'Prediction Assignment Writeup', 'Course Project Prediction Quiz'],)",https://www.coursera.org/learn/practical-machine-learning,"1,570","(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['9 videos', ', ', '3 readings', '9 videos', '5 videos', '4 videos', ', ', '2 readings'],)","(['Week 1: Prediction, Errors, and Cross Validation', 'Week 2: The Caret Package', 'Week 3: Predicting with trees, Random Forests, & Model Based Predictions', 'Week 4: Regularized Regression and Combining Predictors'],)"
"(['This module delves into a wider variety of supervised learning methods for both classification and regression, learning about the connection between model complexity and generalization performance, the importance of proper feature scaling, and how to control model complexity by applying techniques like regularization to avoid overfitting.  In addition to k-nearest neighbors, this week covers linear regression (least-squares, ridge, lasso, and polynomial regression), logistic regression, support vector machines, the use of cross-validation for model evaluation, and decision trees. ', 'This module covers more advanced supervised learning methods that include ensembles of trees (random forests, gradient boosted trees), and neural networks (with an optional summary on deep learning).  You will also learn about the critical problem of data leakage in machine learning and how to detect and avoid it.'],)","(['This course is part of \xe2\x80\x9cApplied Data Science with Python\xe2\x80\x9c and is intended for learners who have basic python or programming background, and want to apply statistics, machine learning, information visualization, social network analysis, and text analysis techniques to gain new insight into data.\n\nOnly minimal statistics background is expected, and the first course contains a refresh of these basic concepts. There are no geographic restrictions. Learners with a formal training in Computer Science but without formal training in data science will still find the skills they acquire in these courses valuable in their studies and careers.'],)","(['This course will introduce the learner to applied machine learning, focusing more on the techniques and methods than on the statistics behind these methods. The course will start with a discussion of how machine learning is different than descriptive statistics, and introduce the scikit learn toolkit. The issue of dimensionality of data will be discussed, and the task of clustering data, as well as evaluating those clusters, will be tackled. Supervised approaches for creating predictive models will be described, and learners will be able to apply the scikit learn predictive modelling methods while understanding process issues related to data generalizability (e.g. cross validation, overfitting). The course will end with a look at more advanced techniques, such as building ensembles, and practical limitations of predictive models. By the end of this course, students will be able to identify the difference between a supervised (classification) and unsupervised (clustering) technique, identify which technique they need to apply for a particular dataset and need, engineer features to meet that need, and write python code to carry out an analysis.\n\nThis course should be taken after Introduction to Data Science in Python and Applied Plotting, Charting & Data Representation in Python and before Applied Text Mining in Python and Applied Social Analysis in Python.'],)","(['English'],)","(['University of Michigan'],)","(['Applied Machine Learning in Python'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/f8/d9a0901e1411e6b4be05fc1f155449/python_datascience_thumbnail_machinelearning_1x1.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Kevyn Collins-Thompson'],)","(['Module 1 Quiz', 'Assignment 1 Submission', 'Module 2 Quiz', 'Assignment 2 Submission', 'Module 3 Quiz', 'Assignment 3 Submission', 'Module 4 Quiz', 'Assignment 4 Submission'],)",https://www.coursera.org/learn/python-machine-learning,"1,013","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Intermediate', 'Pass all graded assignments to complete the course.'],)","(['6 videos', ', ', '4 readings', '12 videos', ', ', '2 readings', '7 videos', ', ', '1 reading', '10 videos', ', ', '11 readings'],)","(['Module 1: Fundamentals of Machine Learning - Intro to SciKit Learn', 'Module 2: Supervised Machine Learning - Part 1', 'Module 3: Evaluation', 'Module 4: Supervised Machine Learning - Part 2'],)"
"(['Machine learning is everywhere, but is often operating behind the scenes. <p>This introduction to the specialization provides you with insights into the power of machine learning, and the multitude of intelligent applications you personally will be able to develop and deploy upon completion.</p>We also discuss who we are, how we got here, and our view of the future of intelligent applications.', 'This week you will build your first intelligent application that makes predictions from data.<p>We will explore this idea within the context of our first case study, predicting house prices, where you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  <p>This is just one of the many places where regression can be applied.Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.</p>You will also examine how to analyze the performance of your predictive model and implement regression in practice using an iPython notebook.', 'How do you guess whether a person felt positively or negatively about an experience, just from a short review they wrote?<p>In our second case study, analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).This task is an example of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification.</p>You will analyze the accuracy of your classifier, implement an actual classifier in an iPython notebook, and take a first stab at a core piece of the intelligent application you will build and deploy in your capstone.  ', 'A reader is interested in a specific news article and you want to find a similar articles to recommend.  What is the right notion of similarity?  How do I automatically search over documents to find the one that is most similar?  How do I quantitatively represent the documents in the first place?<p>In this third case study, retrieving documents, you will examine various document representations and an algorithm to retrieve the most similar subset.  You will also consider structured representations of the documents that automatically group articles by similarity (e.g., document topic).</p>You will actually build an intelligent document retrieval system for Wikipedia entries in an iPython notebook.', 'Ever wonder how Amazon forms its personalized product recommendations?  How Netflix suggests movies to watch?  How Pandora selects the next song to stream?  How Facebook or LinkedIn finds people you might connect with?  Underlying all of these technologies for personalized content is something called collaborative filtering. <p>You will learn how to build such a recommender system using a variety of techniques, and explore their tradeoffs.</p> One method we examine is matrix factorization, which learns features of users and products to form recommendations.  In an iPython notebook, you will use these techniques to build a real song recommender system.', 'You ve probably heard that Deep Learning is making news across the world as one of the most promising techniques in machine learning. Every industry is dedicating resources to unlock the deep learning potential, including for tasks such as image tagging, object recognition, speech recognition, and text analysis.<p>In our final case study, searching for images, you will learn how layers of neural networks provide very descriptive (non-linear) features that provide impressive performance in image classification and retrieval tasks.  You will then construct deep features, a transfer learning technique that allows you to use deep learning very easily, even when you have little data to train the model.</p>Using iPhython notebooks, you will build an image classifier and an intelligent image retrieval system with deep learning.   ', ""In the conclusion of the course, we will describe the final stage in turning our machine learning tools into a service: deployment.<p>We will also discuss some open challenges that the field of machine learning still faces, and where we think machine learning is heading.  We conclude with an overview of what's in store for you in the rest of the specialization, and the amazing intelligent applications that are ahead for us as we evolve machine learning.  ""],)","([],)","(['Do you have data and wonder what it can tell you?  Do you need a deeper understanding of the core ways in which machine learning can improve your business?  Do you want to be able to converse with specialists about anything from regression and classification to deep learning and recommender systems?\n\nIn this course, you will get hands-on experience with machine learning from a series of practical case-studies.  At the end of the first course you will have studied how to predict house prices based on house-level features, analyze sentiment from user reviews, retrieve documents of interest, recommend products, and search for images.  Through hands-on practice with these use cases, you will be able to apply machine learning methods in a wide range of domains.\n\nThis first course treats the machine learning method as a black box.  Using this abstraction, you will focus on understanding tasks of interest, matching these tasks to machine learning tools, and assessing the quality of the output. In subsequent courses, you will delve into the components of this black box by examining models and algorithms.  Together, these pieces form the machine learning pipeline, which you will use in developing intelligent applications.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Identify potential applications of machine learning in practice.  \n   -Describe the core differences in analyses enabled by regression, classification, and clustering.\n   -Select the appropriate machine learning task for a potential application.  \n   -Apply regression, classification, clustering, retrieval, recommender systems, and deep learning.\n   -Represent your data as features to serve as input to machine learning models. \n   -Assess the model quality in terms of relevant error metrics for each task.\n   -Utilize a dataset to fit a model to analyze new data.\n   -Build an end-to-end application that uses machine learning at its core.  \n   -Implement these techniques in Python.'],)","(['English'],)","(['University of Washington'],)","(['Machine Learning Foundations: A Case Study Approach'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/e4/3283d04d0111e5970145eef7ee0b59/gears-818461_1280.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Carlos Guestrin', 'Emily Fox'],)","(['Regression', 'Predicting house prices', 'Classification', 'Analyzing product sentiment', 'Clustering and Similarity', 'Retrieving Wikipedia articles', 'Recommender Systems', 'Recommending songs', 'Deep Learning', 'Deep features for image retrieval'],)",https://www.coursera.org/learn/ml-foundations,"6,256","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['6 weeks of study, 5-8 hours/week', 'Pass all graded assignments to complete the course.'],)","(['18 videos', ', ', '6 readings', '19 videos', ', ', '3 readings', '19 videos', ', ', '3 readings', '17 videos', ', ', '3 readings', '19 videos', ', ', '3 readings', '18 videos', ', ', '4 readings', '7 videos', ', ', '1 reading'],)","(['Welcome', 'Regression: Predicting House Prices', 'Classification: Analyzing Sentiment', 'Clustering and Similarity: Retrieving Documents', 'Recommending Products', 'Deep Learning: Searching for Images', 'Closing Remarks'],)"
"([],)","([],)","([],)","([],)","([],)","([],)",,"([],)","([],)",https://www.coursera.org/specializations/machine-learning,,"([],)","([],)","([],)","([],)"
"(['Welcome to Machine Learning! In this module, we introduce the core idea of teaching a computer to learn concepts using data\xe2\x80\x94without being explicitly programmed. The Course Wiki is under construction. Please visit the resources tab for the most complete and up-to-date information.', 'This course includes programming assignments designed to help you understand how to implement the learning algorithms in practice. To complete the programming assignments, you will need to use Octave or MATLAB. This module introduces Octave/Matlab and shows you how to submit an assignment.', 'Logistic regression is a method for classifying data into discrete outcomes. For example, we might use logistic regression to classify an email  as spam or not spam. In this module, we introduce the notion of classification, the cost function for logistic regression, and the application of logistic regression to multi-class classification.\n', 'Neural networks is a model inspired by how the brain works. It is widely used today in many applications: when your phone interprets and understand your voice commands, it is likely that a neural network is helping to understand your speech; when you cash a check, the machines that automatically read the digits also use neural networks. ', 'To optimize a machine learning algorithm, you ll need to first understand where the biggest improvements can be made. In this module, we discuss how to understand the performance of a machine learning system with multiple parts, and also how to deal with skewed data.\n', 'Given a large number of data points, we may sometimes want to figure out which ones vary significantly from the average. For example, in manufacturing, we may want to detect defects or anomalies. We show how a dataset can be modeled using a Gaussian distribution, and how the model can be used for anomaly detection.\n', 'When you buy a product online, most websites automatically recommend other products that you may like. Recommender systems look at patterns of activities between different users and different products to produce these recommendations. In this module, we introduce recommender algorithms such as the collaborative filtering algorithm and low-rank matrix factorization.'],)","([],)","([""Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI.\n\nThis course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.""],)","(['English'],)","(['Stanford University'],)","(['Machine Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/ml/large-icon.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Andrew Ng'],)","(['Introduction', 'Linear Regression with One Variable', 'Linear Regression with Multiple Variables', 'Octave/Matlab Tutorial', 'Logistic Regression', 'Regularization', 'Neural Networks: Representation', 'Neural Networks: Learning', 'Advice for Applying Machine Learning', 'Machine Learning System Design', 'Support Vector Machines', 'Unsupervised Learning', 'Principal Component Analysis', 'Anomaly Detection', 'Recommender Systems', 'Large Scale Machine Learning', 'Application: Photo OCR'],)",https://www.coursera.org/learn/machine-learning,"57,925","(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['5 videos', ', ', '9 readings', '7 videos', ', ', '8 readings', '6 videos', ', ', '7 readings', ', ', '1 practice quiz', '8 videos', ', ', '16 readings', '6 videos', ', ', '1 reading', '7 videos', ', ', '8 readings', '4 videos', ', ', '5 readings', '7 videos', ', ', '6 readings', '8 videos', ', ', '8 readings', '7 videos', ', ', '7 readings', '5 videos', ', ', '3 readings', '6 videos', ', ', '1 reading', '5 videos', ', ', '1 reading', '7 videos', ', ', '1 reading', '8 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '5 videos', ', ', '1 reading'],)","(['Introduction', 'Linear Regression with One Variable', 'Linear Algebra Review', 'Linear Regression with Multiple Variables', 'Octave/Matlab Tutorial', 'Logistic Regression', 'Regularization', 'Neural Networks: Representation', 'Neural Networks: Learning', 'Advice for Applying Machine Learning', 'Machine Learning System Design', 'Support Vector Machines', 'Unsupervised Learning', 'Dimensionality Reduction', 'Anomaly Detection', 'Recommender Systems', 'Large Scale Machine Learning', 'Application Example: Photo OCR'],)"
"(['Classification is one of the most widely used techniques in machine learning, with a broad array of applications, including sentiment analysis, ad targeting, spam detection, risk assessment, medical diagnosis and image classification. The core goal of classification is to predict a category or class y from some inputs x. Through this course, you will become familiar with the fundamental models and algorithms used in classification, as well as a number of core machine learning concepts. Rather than covering all aspects of classification, you will focus on a few core techniques, which are widely used in the real-world to get state-of-the-art performance. By following our hands-on approach, you will implement your own algorithms on multiple real-world tasks, and deeply grasp the core techniques needed to be successful with these approaches in practice. This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.', 'Linear classifiers are amongst the most practical classification methods. For example, in our sentiment analysis case-study, a linear classifier associates a coefficient with the counts of each word in the sentence. In this module, you will become proficient in this type of representation. You will focus on a particularly useful type of linear classifier called logistic regression, which, in addition to allowing you to predict a class, provides a probability associated with the prediction. These probabilities are extremely useful, since they provide a degree of confidence in the predictions. In this module, you will also be able to construct features from categorical inputs, and to tackle classification problems with more than two class (multiclass problems). You will examine the results of these techniques on a real-world product sentiment analysis task.', 'Once familiar with linear classifiers and logistic regression, you can now dive in and write your first learning algorithm for classification. In particular, you will use gradient ascent to learn the coefficients of your classifier from data. You first will need to define the quality metric for these tasks using an approach called maximum likelihood estimation (MLE). You will also become familiar with a simple technique for selecting the step size for gradient ascent. An optional, advanced part of this module will cover the derivation of the gradient for logistic regression.  You will implement your own learning algorithm for logistic regression from scratch, and use it to learn a sentiment analysis classifier.', ""As we saw in the regression course, overfitting is perhaps the most significant challenge you will face as you apply machine learning approaches in practice. This challenge can be particularly significant for logistic regression, as you will discover in this module, since we not only risk getting an overly complex decision boundary, but your classifier can also become overly confident about the probabilities it predicts. In this module, you will investigate overfitting in classification in significant detail, and obtain broad practical insights from some interesting visualizations of the classifiers' outputs. You will then add a regularization term to your optimization to mitigate overfitting. You will investigate both L2 regularization to penalize large coefficient values, and L1 regularization to obtain additional sparsity in the coefficients. Finally, you will modify your gradient ascent algorithm to learn regularized logistic regression classifiers. You will implement your own regularized logistic regression classifier from scratch, and investigate the impact of the L2 penalty on real-world sentiment analysis data."", 'Along with linear classifiers, decision trees are amongst the most widely used classification techniques in the real world. This method is extremely intuitive, simple to implement and provides interpretable predictions. In this module, you will become familiar with the core decision trees representation. You will then design a simple, recursive greedy algorithm to learn decision trees from data. Finally, you will extend this approach to deal with continuous inputs, a fundamental requirement for practical problems. In this module, you will investigate a brand new case-study in the financial sector: predicting the risk associated with a bank loan. You will implement your own decision tree learning algorithm on real loan data.', ""Out of all machine learning techniques, decision trees are amongst the most prone to overfitting. No practical implementation is possible without including approaches that mitigate this challenge. In this module, through various visualizations and investigations, you will investigate why decision trees suffer from significant overfitting problems. Using the principle of Occam's razor, you will mitigate overfitting by learning simpler trees. At first, you will design algorithms that stop the learning process before the decision trees become overly complex. In an optional segment, you will design a very practical approach that learns an overly-complex tree, and then simplifies it with pruning. Your implementation will investigate the effect of these techniques on mitigating overfitting on our real-world loan data set. "", 'Real-world machine learning problems are fraught with missing data. That is, very often, some of the inputs are not observed for all data points. This challenge is very significant, happens in most cases, and needs to be addressed carefully to obtain great performance. And, this issue is rarely discussed in machine learning courses. In this module, you will tackle the missing data challenge head on. You will start with the two most basic techniques to convert a dataset with missing data into a clean dataset, namely skipping missing values and inputing missing values. In an advanced section, you will also design a modification of the decision tree learning algorithm that builds decisions about missing data right into the model. You will also explore these techniques in your real-data implementation.  ', ""One of the most exciting theoretical questions that have been asked about machine learning is whether simple classifiers can be combined into a highly accurate ensemble. This question lead to the developing of boosting, one of the most important and practical techniques in machine learning today. This simple approach can boost the accuracy of any classifier, and is widely used in practice, e.g., it's used by more than half of the teams who win the Kaggle machine learning competitions. In this module, you will first define the ensemble classifier, where multiple models vote on the best prediction. You will then explore a boosting algorithm called  AdaBoost, which provides a great approach for boosting classifiers. Through visualizations, you will become familiar with many of the practical aspects of this techniques. You will create your very own implementation of AdaBoost, from scratch, and use it to boost the performance of your loan risk predictor on real data. "", 'In many real-world settings, accuracy or error are not the best quality metrics for classification. You will explore a case-study that significantly highlights this issue: using sentiment analysis to display positive reviews on a restaurant website. Instead of accuracy, you will define two metrics: precision and recall, which are widely used in real-world applications to measure the quality of classifiers. You will explore how the probabilities output by your classifier can be used to trade-off precision with recall, and dive into this spectrum, using precision-recall curves. In your hands-on implementation, you will compute these metrics with your learned classifier on real-world sentiment analysis data.', 'With the advent of the internet, the growth of social media, and the embedding of sensors in the world, the magnitudes of data that our machine learning algorithms must handle have grown tremendously over the last decade. This effect is sometimes called ""Big Data"". Thus, our learning algorithms must scale to bigger and bigger datasets. In this module, you will develop a small modification of gradient ascent called stochastic gradient, which provides significant speedups in the running time of our algorithms. This simple change can drastically improve scaling, but makes the algorithm less stable and harder to use in practice. In this module, you will investigate the practical techniques needed to make stochastic gradient viable, and to thus to obtain learning algorithms that scale to huge datasets. You will also address a new kind of machine learning problem, online learning, where the data streams in over time, and we must learn the coefficients as the data arrives. This task can also be solved with stochastic gradient. You will implement your very own stochastic gradient ascent algorithm for logistic regression from scratch, and evaluate it on sentiment analysis data. '],)","([],)","([""Case Studies: Analyzing Sentiment & Loan Default Prediction\n\nIn our case study on analyzing sentiment, you will create models that predict a class (positive/negative sentiment) from input features (text of the reviews, user profile information,...).  In our second case study for this course, loan default prediction, you will tackle financial data, and predict when a loan is likely to be risky or safe for the bank. These tasks are an examples of classification, one of the most widely used areas of machine learning, with a broad array of applications, including ad targeting, spam detection, medical diagnosis and image classification. \n\nIn this course, you will create classifiers that provide state-of-the-art performance on a variety of tasks.  You will become familiar with  the most successful techniques, which are most widely used in practice, including logistic regression, decision trees and boosting.  In addition, you will be able to design and implement the underlying algorithms that can learn these models at scale, using stochastic gradient ascent.  You will implement these technique on real-world, large-scale machine learning tasks.  You will also address significant tasks you will face in real-world applications of ML, including handling missing data and measuring precision and recall to evaluate a classifier.  This course is hands-on, action-packed, and full of visualizations and illustrations of how these techniques will behave on real data.  We've also included optional content in every module, covering advanced topics for those who want to go even deeper! \n\nLearning Objectives: By the end of this course, you will be able to:\n   -Describe the input and output of a classification model.\n   -Tackle both binary and multiclass classification problems.\n   -Implement a logistic regression model for large-scale classification.  \n   -Create a non-linear model using decision trees.\n   -Improve the performance of any model using boosting.\n   -Scale your methods with stochastic gradient ascent.\n   -Describe the underlying decision boundaries.  \n   -Build a classification model to predict sentiment in a product review dataset.  \n   -Analyze financial data to predict loan defaults.\n   -Use techniques for handling missing data.\n   -Evaluate your models using precision-recall metrics.\n   -Implement these techniques in Python (or in the language of your choice, though Python is highly recommended).""],)","(['English'],)","(['University of Washington'],)","(['Machine Learning: Classification'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/b1/37a1a04d0011e59bd777c2a1ef6a6e/gears-818461_1280.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Carlos Guestrin', 'Emily Fox'],)","(['Linear Classifiers & Logistic Regression', 'Predicting sentiment from product reviews', 'Learning Linear Classifiers', 'Implementing logistic regression from scratch', 'Overfitting & Regularization in Logistic Regression', 'Logistic Regression with L2 regularization', 'Decision Trees', 'Identifying safe loans with decision trees', 'Implementing binary decision trees', 'Preventing Overfitting in Decision Trees', 'Decision Trees in Practice', 'Handling Missing Data', 'Exploring Ensemble Methods', 'Boosting', 'Boosting a decision stump', 'Precision-Recall', 'Exploring precision and recall', 'Scaling to Huge Datasets & Online Learning', 'Training Logistic Regression via Stochastic Gradient Ascent'],)",https://www.coursera.org/learn/ml-classification,"1,925","(['Rated 4.7 out of 5 of ', ' ratings'],)","(['7 weeks of study, 5-8 hours/week', 'Pass all graded assignments to complete the course.'],)","(['8 videos', ', ', '2 readings', '18 videos', ', ', '2 readings', '18 videos', ', ', '2 readings', '13 videos', ', ', '2 readings', '13 videos', ', ', '3 readings', '8 videos', ', ', '2 readings', '6 videos', ', ', '1 reading', '13 videos', ', ', '3 readings', '8 videos', ', ', '2 readings', '16 videos', ', ', '2 readings'],)","(['Welcome!', 'Linear Classifiers & Logistic Regression', 'Learning Linear Classifiers', 'Overfitting & Regularization in Logistic Regression', 'Decision Trees', 'Preventing Overfitting in Decision Trees', 'Handling Missing Data', 'Boosting', 'Precision-Recall', 'Scaling to Huge Datasets & Online Learning'],)"
"(['This first week gives an introduction to the course and asks what it is to be a teacher. This is a chance for you to reflect on you own identity and aspirations as a teacher and gain an informed understanding of the world, or worlds, of childhood. You will build on and extend your existing knowledge as a teacher. We will discuss the ways in which teaching can be defined as a profession and what it means to be a professional teacher.', 'The videos in this week are all related to the theme of children and young people s learning. The emphasis is on thinking \xe2\x80\x98skills  \xe2\x80\x93 learning how to think effectively and creatively. We ask how you as a teacher ensure that students are thinking while they are in your classroom. You will write an essay which brings together the various strands of your learning. This is for your own professional development, but it will also help you to consider what the implications are for teaching and learning in your own classroom.', 'This week is focused on the classroom and asks you to consider the question \xe2\x80\x98How good is my classroom?  It asks you to revisit, replay, and bring together the many ingredients that make a classroom a stimulating place for learning and an enjoyable and engaging place for teaching. We come back to the importance of assessment for learning. As Dylan Wiliam says, \xe2\x80\x98assessment is minute by minute in the classroom , not simply something that happens at the end of the course.', 'This week focuses on ways that we can help children to live and learn in a world of change. We will consider the importance of cultivating creativity and acknowledging multiple types of intelligence. We will also look at learning that takes place informally outside of school. We will identify key features of excellent practice in schools and look at the benefits of professional development. This is the final week of this course. If you have stayed with us to the end, congratulations! This may be an ending but it is also a beginning as you move on to the next course.'],)","([],)","(['Foundations of Teaching for Learning is a program of study primarily for people who are currently teaching but have had no formal teacher education. This course is an introductory one that considers the three domains of being a teacher:  Professional Knowledge and Understanding; Professional Practice; and Professional Values, Relationships and Engagement.'],)","(['English'],)","(['Commonwealth Education Trust'],)","(['Foundations of Teaching for Learning: Introduction'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/83/41f9c04cff11e7a517a190e78ba697/course-introduction.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Professor John MacBeath'],)","(['Quiz 1', 'Quiz 2', 'Reflection on Teaching and Learning', 'Quiz 3', 'Quiz 4', 'Your Learning Story '],)",https://www.coursera.org/learn/teaching,381,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['3-4 hours per week', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '4 readings', '4 videos', ', ', '1 reading', '4 videos', ', ', '1 reading', '4 videos', ', ', '1 reading'],)","(['Being a Teacher: A Professional Privilege', 'Thinking About Learning', 'How Good is My Classroom?', 'Continuing to Learn in a Changing World'],)"
"(['In this module, you will learn how to ask others to eat together and how to respond to similar suggestions in Korean. After completing the lesson, you will be able to introduce your favorite food, describe how certain foods taste, suggest something to do together and respond to a suggestion.', 'In this module, you will learn how to introduce famous shopping areas in Korean. After completing the lesson, you will be able to talk about where you are going to shop, describe various kinds of stores, talk about what you want to buy, and describe shopping districts in detail.'],)","(['Beginner students who are familiar with the Korean alphabet'],)","(['Welcome to Learn to Speak Korean 1!\n \nThis course is for beginner students who are familiar with the Korean alphabet, Hangeul. Through this course students will learn the skills essential for daily interactions with Koreans while living in Korea. \n\nThis course consists of six modules, and each module is composed of five units. Each unit has vocabulary, grammar and expressions, conversation practice, video clips, quizzes, a workbook, and vocabulary lists. In order to assist students with their independent studies, Korean learning materials such as lecture notes, workbooks, and vocabulary lists detailing each day\xe2\x80\x99s lecture are also provided. The vocabulary lists are accompanied by English, Chinese, and Japanese translations.\n\nI hope that you enjoy all this program has to offer over the next six weeks. After studying in this program, you will be able to have a real Korean conversation with your newly acquired knowledge of the Korean language. Thank you!\n\nYour Course Team\n\nChief Contents Developer: Sang Mee Han\nContents Developers: Bock Ja Lee, Yoo Kyung Choi, Ha Min Cho,  Ju Eun Kim\nProduction Assistants: Jin Hee Kim, Eun Hye Kim'],)","(['English'],)","(['Yonsei University'],)","(['Learn to Speak Korean 1'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/6b/0bbd403c3a11e687d7cff9394dce84/logo4.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Sang Mee Han'],)","(['Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5', 'Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5', 'Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5', 'Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5', 'Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5', 'Graded Quiz 1', 'Graded Quiz 2', 'Graded Quiz 3', 'Graded Quiz 4', 'Graded Quiz 5'],)",https://www.coursera.org/learn/learn-speak-korean1,876,"(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Beginner', '6 weeks of study, 2-4 hours/week', 'Pass all graded assignments to complete the course.'],)","(['6 videos', ', ', '11 readings', '5 videos', ', ', '11 readings', '5 videos', ', ', '11 readings', '5 videos', ', ', '11 readings', '5 videos', ', ', '11 readings', '5 videos', ', ', '11 readings'],)","([""Introducing One's Friends"", ""Introducing One's Hometown"", 'Introducing Food', 'Ordering Food', 'Introducing Places to Shop ', 'Shopping'],)"
"([""For the course \xe2\x80\x9cDeep Learning for Business,\xe2\x80\x9d the first module is \xe2\x80\x9cDeep Learning Products & Services,\xe2\x80\x9d which starts with the lecture \xe2\x80\x9cFuture Industry Evolution & Artificial Intelligence\xe2\x80\x9d that explains past, current, and future industry evolutions and how DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of future industry in the near future. The following lectures look into the hottest DL and ML products and services that are exciting the business world. First, the \xe2\x80\x9cJeopardy!\xe2\x80\x9d winning versatile IBM Watson is introduced along with its DeepQA and AdaptWatson systems that use DL technology. Then the Amazon Echo and Echo Dot products are introduced along with the Alexa cloud based DL personal assistant that uses ASR (Automated Speech Recognition) and NLU (Natural Language Understanding) technology. The next lecture focuses on LettuceBot, which is a DL system that plants lettuce seeds with automatic fertilizer and herbicide nozzles control. Then the computer vision based DL blood cells analysis diagnostic system Athelas is introduced followed by the introduction of a classical and symphonic music composing DL system named AIVA (Artificial Intelligence Virtual Artist). As the last topic of module 1, the upcoming Apple watchOS 4 and the HomePod speaker that was presented at Apple's 2017 WWDC (World Wide Developers Conference) is introduced."", 'The second module \xe2\x80\x9cBusiness with Deep Learning & Machine Learning\xe2\x80\x9d first focuses on various business considerations based on changes to come due to DL (Deep Learning) and ML (Machine Learning) technology in the lecture \xe2\x80\x9cBusiness Considerations in the Machine Learning Era.\xe2\x80\x9d In the following lecture \xe2\x80\x9cBusiness Strategy with Machine Learning & Deep Learning\xe2\x80\x9d explains the changes that are needed to be more successful in business, and provides an example of business strategy modeling based on the three stages of preparation, business modeling, and model rechecking & adaptation. The next lecture \xe2\x80\x9cWhy is Deep Learning Popular Now?\xe2\x80\x9d explains the changes in recent technology and support systems that enable the DL systems to perform with amazing speed, accuracy, and reliability. The last lecture \xe2\x80\x9cCharacteristics of Businesses with DL & ML\xe2\x80\x9d first explains DL and ML based business characteristics based on data types, followed by DL & ML deployment options, the competitive landscape, and future opportunities are also introduced.', 'The third module \xe2\x80\x9cDeep Learning Computing Systems & Software\xe2\x80\x9d focuses on the most significant DL (Deep Learning) and ML (Machine Learning) systems and software. Except for the NVIDIA DGX-1, the introduced DL systems and software in this module are not for sale, and therefore, may not seem to be important for business at first glance. But in reality, the companies that created these systems and software are indeed the true leaders of the future DL and ML business era. Therefore, this module introduces the true state-of-the-art level of DL and ML technology. The first lecture introduces the most popular DL open source software TensorFlow, CNTK (Cognitive Toolkit), Keras, Caffe, Theano, and their characteristics. Due to their popularly, strong influence, and diverse capabilities, the following lectures introduce the details of Google TensorFlow and Microsoft CNTK. Next, NVIDIA s supercomputer DGX-1, that has fully integrated customized DL hardware and software, is introduced. In the following lectures, the most interesting competition of human versus machine is introduced in the Google AlphaGo lecture, and in the ILSVRC (ImageNet Large Scale Visual Recognition Challenge) lecture, the results of competition between cutting edge DL systems is introduced and the winning performance for each year is compared.', 'The module \xe2\x80\x9cBasics of Deep Learning Neural Networks\xe2\x80\x9d first focuses on explaining the technical differences of AI (Artificial Intelligence), ML (Machine Learning), and DL (Deep Learning) in the first lecture titled \xe2\x80\x9cWhat is DL (Deep Learning) and ML (Machine Learning).\xe2\x80\x9d In addition, the characteristics of CPUs (Central Processing Units) and GPUs (Graphics Processing Units) used in DL as well as the representative computer performance units of FLOPS (FLoating-Point Operations Per Second) and IPS (Instructions Per Second) are introduced. Next, in the NN (Neural Network) lecture, the biological neuron (nerve cell) and its signal transfer is introduced followed by an ANN (Artificial Neural Network) model of a neuron based on a threshold logic unit and soft output activation functions is introduced. Then the extended NN technologies that uses MLP (Multi-Layer Perceptron), SoftMax, and AutoEncoder are explained. In the last lecture of the module, NN learning based on backpropagation is introduced along with the learning method types, which include supervised learning, unsupervised learning, semi-supervised learning, and reinforcement learning.', ""The module \xe2\x80\x9cDeep Learning with CNN & RNN\xe2\x80\x9d focuses on CNN (Convolutional Neural Network) and RNN (Recurrent Neural Network) technology that enable DL (Deep Learning). First the lectures introduce how CNNs used in image/video recognition, recommender systems, natural language processing, and games (like Chess and Go) are made possible through processing in the convolutional layer and feature maps. The lecture also introduces how CNNs use subsampling (pooling), LCN (Local Contrast Normalization), dropout, ensemble, and bagging technology to become more efficient, reliable, robust, and accurate. Next, the lectures introduce how DL with RNN is used in speech recognition (as in Apple's Siri, Google s Voice Search, and Samsung's S Voice), handwriting recognition, sequence data analysis, and program code generation. Then the details of RNN technologies are introduced, which include S2S (Sequence to Sequence) learning, forward RNN, backward RNN, representation techniques, context based projection, and representation with attention. As the last part of the module, the early model of RNN, which is the FRNN (Fully Recurrent NN), and the currently popular RNN model LSTM (Long Short-Term Memory) is introduced."", 'The module \xe2\x80\x9cDeep Learning Project with TensorFlow Playground\xe2\x80\x9d focuses on four NN (Neural Network) design projects, where experience on designing DL (Deep Learning) NNs can be gained using a fun and powerful application called the TensorFlow Playground. The lectures first teach how to use the TensorFlow Playground, which is followed by guidance on three projects so you can easily buildup experience on using the TensorFlow Playground system. Then in Project 4 a \xe2\x80\x9cDL NN Design Challenge\xe2\x80\x9d is given, where you will need to make the NN \xe2\x80\x9cDeeper\xe2\x80\x9d by adding hidden layers and neurons to satisfy the classification objectives. The knowledge you obtained in the lecture of Modules 1~5 will be used in these projects.'],)","([],)","(['Your smartphone, smartwatch, and automobile (if it is a newer model) have AI (Artificial Intelligence) inside serving you every day. In the near future, more advanced \xe2\x80\x9cself-learning\xe2\x80\x9d capable DL (Deep Learning) and ML (Machine Learning) technology will be used in almost every aspect of your business and industry. So now is the right time to learn what DL and ML is and how to use it in advantage of your company. This course has three parts, where the first part focuses on DL and ML technology based future business strategy including details on new state-of-the-art products/services and open source DL software, which are the future enablers. The second part focuses on the core technologies of DL and ML systems, which include NN (Neural Network), CNN (Convolutional NN), and RNN (Recurrent NN) systems. The third part focuses on four TensorFlow Playground projects, where experience on designing DL NNs can be gained using an easy and fun yet very powerful application called the TensorFlow Playground. This course was designed to help you build business strategies and enable you to conduct technical planning on new DL and ML services and products.'],)","(['English'],)","(['Yonsei University'],)","(['Deep Learning for Business'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/d4/190440653911e7b5ddcbc8c971bacc/jmc_thum_DeepLearning.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Jong-Moon Chung'],)","(['Graded Quiz', 'Graded Quiz', 'Graded Quiz', 'Graded Quiz', 'Graded Quiz'],)",https://www.coursera.org/learn/deep-learning-business,61,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Beginner', 'Pass all graded assignments to complete the course.'],)","(['5 videos', ', ', '1 practice quiz', '4 videos', ', ', '1 practice quiz', '4 videos', ', ', '1 practice quiz', '3 videos', ', ', '1 practice quiz', '2 videos', ', ', '1 practice quiz', '3 videos'],)","(['Deep Learning Products & Services ', 'Business with Deep Learning & Machine Learning', 'Deep Learning Computing Systems & Software', 'Basics of Deep Learning Neural Networks', 'Deep Learning with CNN & RNN ', 'Deep Learning Project with  TensorFlow Playground'],)"
"([],)","(['This course is for those who are interested in NLP field and want to know the current state-of-the-art in research and production. We expect that you have already taken some courses on machine learning and deep learning, but probably have never applied those models to texts and want to get a quick start.'],)","(['This course covers a wide range of tasks in Natural Language Processing from basic to advanced: sentiment analysis, summarization, dialogue state tracking, to name a few. Upon completing, you will be able to recognize NLP tasks in your day-to-day work, propose approaches, and judge what techniques are likely to work well.  The final project is devoted to one of the most hot topics in today\xe2\x80\x99s NLP. You will build your own conversational chat-bot that will assist with search on StackOverflow website. The project will be based on practical assignments of the course, that will give you hands-on experience with such tasks as text classification, named entities recognition, and duplicates detection. \n\nThroughout the lectures, we will aim at finding a balance between traditional and deep learning techniques in NLP and cover them in parallel. For example, we will discuss word alignment models in machine translation and see how similar it is to attention mechanism in encoder-decoder neural networks. Core techniques are not treated as black boxes. On the contrary, you will get in-depth understanding of what\xe2\x80\x99s happening inside. To succeed in that, we expect your familiarity with the basics of linear algebra and probability theory, machine learning setup, and deep neural networks. Some materials are based on one-month-old papers and introduce you to the very state-of-the-art in NLP research.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Natural Language Processing'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/df/324a90b06511e7958c7f63f0f736f7/Natural-language-processing-.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Anna Potapenko', 'Alexey Zobnin', 'Anna Kozlova', 'Sergey Yudin', 'Andrei Zimovnov'],)","([],)",https://www.coursera.org/learn/language-processing,,"([],)","(['Advanced', '5 weeks of study', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","([],)","([],)","([],)","([],)","([],)",,"([],)","([],)",https://www.coursera.org/specializations/learn-spanish,,"([],)","([],)","([],)","([],)"
"([],)","([],)","([],)","([],)","([],)","([],)",,"([],)","([],)",https://www.coursera.org/specializations/learn-mandarin,,"([],)","([],)","([],)","([],)"
"([],)","(['This advanced undergraduate course provides a molecular-level understanding of thermodynamics and covers the application of statistical thermodynamics to several important engineering and biological systems.'],)","(['Modern engineering research focuses on designing new materials and processes at the molecular level. Statistical thermodynamics provides the formalism for understanding how molecular interactions lead to the observed collective behavior at the macroscale. \n\nThis course will develop a molecular-level understanding of key thermodynamic quantities like heat, work, free energy and entropy. These concepts will be applied in understanding several important engineering and biological applications.'],)","(['English'],)","(['Carnegie Mellon University'],)","(['Statistical Thermodynamics: Molecules to Machines'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/a5/aff3a0ce4311e49136915d63055160/logo_notitle.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Venkat Viswanathan'],)","(['Assignment 1', 'Assignment 2', 'Assignment 3', 'Assignment 4', 'Assignment 5', 'Assignment 6'],)",https://www.coursera.org/learn/statistical-thermodynamics-cm,24,"(['Rated 3.8 out of 5 of ', ' ratings'],)","(['Intermediate', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '2 practice quizzes', '2 videos', '5 videos', '3 videos', '3 videos', '3 videos', '4 videos', '1 video'],)","(['Theory: Classical Thermodynamics', 'Theory: Introduction to Statistics and Statistical Thermodynamics', 'Theory: Non-interacting systems', 'Theory: Interacting systems', 'Applications: Water, Polymer and Photosynthesis', 'Applications: Photosynthesis, Liquids', 'Application: Adsorption, Electrolytes', 'Thank You'],)"
"(['The purpose of this module is to introduce spectrum of sensors used to implement intelligent machining. The module will also discuss the basics of signal processing and analysis techniques that has brought intelligent machining paradigm closer to industrial realization. Following issues pertaining to sensors and sensing techniques will be elaborated up: (1) Which sensors are to be used in each application? (2) How to acquire and process sensor signals? \n'],)","(['This course is for anyone interested in how digital advances are changing the landscape and capabilities of manufacturing, from high school graduates exploring careers to operations managers and business owners hungry for an understanding of the newest manufacturing technologies.'],)","(['Manufacturers are increasingly utilizing machine tools that are self-aware \xe2\x80\x93 they perceive their own states and the state of the surrounding environment \xe2\x80\x93 and are able to make decisions related to machine activity processes. This is called intelligent machining, and through this course students will receive a primer on its background, tools and related terminology. \n\nLearn how the integration of smart sensors and controls are helping to improve productivity. You\xe2\x80\x99ll be exposed to various sensors and sensing techniques, process control strategies, and open architecture systems that can be leveraged to enable intelligent machining. This course will prepare you to contribute to the implementation of intelligent machining projects. \n\nMain concepts of this course will be delivered through lectures, readings, discussions and various videos. \n\nThis is the fifth course in the Digital Manufacturing & Design Technology specialization that explores the many facets of manufacturing\xe2\x80\x99s \xe2\x80\x9cFourth Revolution,\xe2\x80\x9d and features a culminating project involving creation of a roadmap to achieve a self-established DMD-related professional goal.\n\nTo learn more about the Digital Manufacturing and Design Technology specialization, please watch the overview video by copying and pasting the following link into your web browser: https://youtu.be/r-VHiwsg_t0'],)","(['English'],)","(['University at Buffalo', 'The State University of New York'],)","(['Intelligent Machining'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/27/5b50d0acdb11e6bd5ebb7f1735cf92/Intelligent-Machining_banner-2.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Rahul Rai'],)","(['Introduction to Intelligent Machining', 'Sensors and Sensing Techniques', 'Process Control Strategies', 'Intelligent Machining- Future Directions '],)",https://www.coursera.org/learn/intelligent-machining,33,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['Beginner', '4 weeks of study, 3 \xc2\xbd hours per week', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '4 readings', ', ', '3 practice quizzes', '4 videos', ', ', '3 readings', ', ', '4 practice quizzes', '4 videos', ', ', '4 readings', ', ', '4 practice quizzes', '3 videos', ', ', '5 readings', ', ', '1 practice quiz'],)","(['Introduction to Intelligent Machining ', 'Sensors and Sensing Techniques', 'Process Control Strategies', 'Future Directions in Advanced Machining'],)"
"(['Welcome to the ""Introduction to Deep Learning"" course! In the first week you\'ll learn about linear models and stochatic optimization methods. Linear models are basic building blocks for many deep architectures, and stochastic optimization is used to learn every model that we\'ll discuss in our course.'],)","(['Developers, analysts and researchers who are faced with tasks involving complex structure understanding such as image, sound and text analysis.'],)","(['The goal of this course is to give learners basic understanding of modern neural networks and their applications in computer vision and natural language understanding. The course starts with a recap of linear models and discussion of stochastic optimization methods that are crucial for training deep neural networks. Learners will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers. \nLearners will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project learner will implement deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.\n\nThe prerequisites for this course are: \n1) Basic knowledge of Python.\n2) Basic linear algebra and probability.\n\nPlease note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:\n1) Linear regression: mean squared error, analytical solution.\n2) Logistic regression: model, cross-entropy loss, class probability estimation.\n3) Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.\n4) The problem of overfitting.\n5) Regularization for linear models.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Introduction to Deep Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/35/83c3d08f2111e7bd2205ef015e40cc/Deep-learning-for-computer-vision.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Evgeny Sokolov', 'Andrei Zimovnov', 'Alexander Panin', 'Ekaterina Lobacheva', 'Nikita Kazeev'],)","(['Linear models', 'Overfitting and regularization', 'Linear models and optimization', 'Logistic regression in TensorFlow', 'my1stNN', 'my1stNN - Keras this time', 'Your very own neural network', 'Convolutions and pooling', 'Your first CNN on CIFAR-10', 'Fine-tuning InceptionV3 for flowers classification', 'Simple autoencoder', 'Word embeddings', 'Generative adversarial networks', 'RNN and Backpropagation', 'Generating names with RNNs', 'Modern RNNs', 'How to use RNNs', 'Image Captioning Final Project', 'Image Captioning Final Project'],)",https://www.coursera.org/learn/intro-to-deep-learning,74,"(['Rated 4.3 out of 5 of ', ' ratings'],)","(['Advanced', '6 weeks of study, 6-10 hours/week', 'Pass all graded assignments to complete the course.'],)","(['7 videos', ', ', '1 reading', '8 videos', ', ', '1 practice quiz', '6 videos', '9 videos', '6 videos', '3 items'],)","(['Introduction to optimization', 'Introduction to neural networks', 'Deep Learning for images', 'Unsupervised representation learning', 'Deep learning for sequences', 'Final Project'],)"
"([],)","(['The course is designed for people\n(1) who already know the basics of machine learning and deep learning \n(2) who have never studied image processing and computer vision and want to fill that gap\n(3) who want to learn how to solve computer vision problems with deep learning. '],)","(['Deep learning added a huge boost to the already rapidly developing field of computer vision. With deep learning, a lot of new applications of computer vision techniques have been introduced and are now becoming parts of our everyday lives. These include face recognition and indexing, photo stylization or machine vision in self-driving cars. \nThe goal of this course is to introduce students to computer vision, starting from basics and then turning to more modern deep learning models. We will cover both image and video recognition, including image classification and annotation, object recognition and image search, various object detection techniques, motion estimation, object tracking in video, human action recognition, and finally image stylization, editing and new image generation. In course project, students will learn how to build face recognition and manipulation system to understand the internal mechanics of this technology, probably the most renown and oftenly demonstrated in movies and TV-shows example of computer vision and AI.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Deep Learning in Computer Vision'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/f4/73a8908f2211e7be561d79af9860d8/Deep-learning-for-computer-vision.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Anton Konushin', 'Alexey Artemov'],)","([],)",https://www.coursera.org/learn/deep-learning-in-computer-vision,,"([],)","(['Advanced', '6 weeks of study', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","(['The course is designed for people  (1) who already know the basics of machine learning and want to broaden their horizons (2) who have never studied the specifics of reinforcement learning and want to fill that gap  (3) who want to understand the methods and details standing behind the breaking AI news.'],)","(['The goal of \xc2\xabIntro to Reinforcement learning\xc2\xbb is in its name: introduce students to reinforcement learning \xe2\x80\x93 the prominent area of modern research in artificial intelligence.  The reinforcement learning differs much from both supervised and unsupervised learning and is more about how humans learn in reality.  \nStudents will learn from this course both theoretical core and recent practical RL methods. Most importantly, they will learn how to apply such methods to practical problems. In six weeks students will be guided through the basics of Reinforcement Learning (RL):  we will talk about essential theory of RL, value-based methods (such as SARSA and Q-learning), policy based algorithms and methods, designed to solve the optimal exploration problem. In addition to algorithms and theory, during the course we will also present useful practical tips and tricks, needed for learning stabilization, and study how to apply the methods to large scale problems with deep neural networks.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Practical Reinforcement Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/b7/5e73908f2211e7a194c734339bf54e/Reinforcement-learning.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Pavel Shvechikov', 'Alexander Panin'],)","([],)",https://www.coursera.org/learn/practical-rl,,"([],)","(['Intermediate', '6 weeks of study', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","(['This class is intended for Data analysts, Data scientists and Business analysts. It is also suitable for IT decision makers evaluating Google Cloud Platform for use by data scientists.\n\nThis class is for people who do the following with big data:\n\n\xe2\x80\xa2 Extracting, Loading, Transforming, cleaning, and validating data for use in analytics\n\xe2\x80\xa2 Designing pipelines and architectures for data processing\n\xe2\x80\xa2 Creating and maintaining machine learning and statistical models\n\xe2\x80\xa2 Querying datasets, visualizing query results and creating reports'],)","(['This 1-week accelerated on-demand course introduces participants to the Big Data and Machine Learning capabilities of Google Cloud Platform (GCP). It provides a quick overview of the Google Cloud Platform and a deeper dive of the data processing capabilities.\n\nAt the end of this course, participants will be able to:\n\xe2\x80\xa2 Identify the purpose and value of the key Big Data and Machine Learning products in the Google Cloud Platform\n\xe2\x80\xa2 Use CloudSQL and Cloud Dataproc to migrate existing MySQL and Hadoop/Pig/Spark/Hive workloads to Google Cloud Platform\n\xe2\x80\xa2 Employ BigQuery and Cloud Datalab to carry out interactive data analysis\n\xe2\x80\xa2 Choose between Cloud SQL, BigTable and Datastore\n\xe2\x80\xa2 Train and use a neural network using TensorFlow\n\xe2\x80\xa2 Choose between different data processing products on the Google Cloud Platform\n\nBefore enrolling in this course, participants should have roughly one (1) year of experience with one or more of the following:\n\xe2\x80\xa2 A common query language such as SQL\n\xe2\x80\xa2 Extract, transform, load activities\n\xe2\x80\xa2 Data modeling\n\xe2\x80\xa2 Machine learning and/or statistics\n\xe2\x80\xa2 Programming in Python\n\nGoogle Account Notes:\n\xe2\x80\xa2 You\'ll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n\xe2\x80\xa2 There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as ""business"" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n\xe2\x80\xa2 More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/'],)","(['English'],)","(['Google Cloud'],)","(['Google Cloud Platform Big Data and Machine Learning Fundamentals'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0d/dfca001e4b11e7b3efcf607d794a33/BD-and-ML-Fundamentals-Header.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Module 1 Review', 'Module 2 Review', 'Module 3 Review', 'Module 4 Review', 'Module 5 Review'],)",https://www.coursera.org/learn/gcp-big-data-ml-fundamentals,"1,115","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Intermediate', '1 week of study, 6-10 hours/week', ""You'll need a Google Cloud Platform Free Trial account. Sign up at: https://cloud.google.com/free/"", 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '9 videos', ', ', '3 readings', '10 videos', ', ', '2 readings', '13 videos', ', ', '4 readings', '4 videos', ', ', '1 reading', '3 videos', ', ', '1 reading'],)","(['Introduction to the Data and Machine Learning on Google Cloud Platform Specialization', 'Module 1: Introduction to Google Cloud Platform and its Big Data Products', 'Module 2: Foundations of GCP Compute and Storage', 'Module 3: Data Analysis on the Cloud', 'Module 4: Scaling Data Analysis: Compute with GCP', 'Module 5: Data Processing Architectures: Scalable Ingest, Transform and Load', 'Module 6: Summary of Google Cloud Platform, Big Data, and ML'],)"
"([],)","(['This course is recommended to those who has been introduced to the Machine Learning methods and skills, and who is interested in applying those to practical scientific research challenges. The field of High Energy Physics is just one fascinating example of modern scientific fields that can be greatly advanced by Machine Learning tools. No special Physics background is required to complete the assignments.'],)","(['The Large Hadron Collider (LHC) is the largest data generation machine for the time being. It doesn\xe2\x80\x99t produce the big data, the data is gigantic. Just one of the four experiments generates thousands gigabytes per second. The intensity of data flow is only going to be increased over the time. So the data processing techniques have to be quite sophisticated and unique. In this course we\xe2\x80\x99ll introduce students into the main concepts of the Physics behind those data flow so the main puzzles of the Universe Physicists are seeking answers for will be much more transparent. Of course we will scrutinize the major stages of the data processing pipelines, and focus on the role of the Machine Learning techniques for such tasks as track pattern recognition, particle identification, online real-time processing (triggers) and search for very rare decays. The assignments of this course will give you opportunity to apply your skills in the search for the New Physics using advanced data analysis techniques. Upon the completion of the course you will understand both the principles of the Experimental Physics and Machine Learning much better.'],)","(['English'],)","(['National Research University Higher School of Economics'],)","(['Addressing Large Hadron Collider Challenges by Machine Learning'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/67/d710b0b06611e78076a36826262d84/LCH_ML.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Andrei Ustyuzhanin', 'Mikhail Hushchyn'],)","([],)",https://www.coursera.org/learn/hadron-collider-machine-learning,,"([],)","(['Advanced', '5 weeks of study', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","(['\xe2\x80\xa2 Data Analysts, Business Analysts, Business Intelligence professionals\n\xe2\x80\xa2 Cloud Data Engineers who will be partnering with Data Analysts to build scalable data solutions on Google Cloud Platform'],)","(['Want to know how to query and process petabytes of data in seconds? Curious about data analysis that scales automatically as your data grows? Welcome to the Data Insights course!\n\nThis 1-week, accelerated online course teaches participants how to derive insights through data analysis and visualization using the Google Cloud Platform. The course features interactive scenarios and hands-on labs where participants explore, mine, load, visualize, and extract insights from diverse Google BigQuery datasets. The course covers data loading, querying, schema modeling, optimizing performance, query pricing,  and data visualization.\n\nPREREQUISITES\nTo get the most out of this course, participants must complete the prior courses in this specialization:\n\xe2\x80\xa2 Exploring and Preparing your Data\n\xe2\x80\xa2 Storing and Visualizing your Data\n\xe2\x80\xa2 Architecture and Performance'],)","(['English'],)","(['Google Cloud'],)","(['Applying Machine Learning to your Data with GCP'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/f1/363100c01b11e7bd54b5d04d7ecb09/header-1.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","([],)",https://www.coursera.org/learn/data-insights-gcp-apply-ml,,"([],)","(['Intermediate', '1 week of study, 5-7 hours/week', ""You'll need a desktop web browser to run this course's interactive labs via Qwiklabs."", 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","(['This class is intended for experienced developers who are responsible for managing big data transformations including 1) Extracting, Loading, Transforming, cleaning, and validating data 2) Designing pipelines and architectures for data processing 3) Creating and maintaining machine learning and statistical models 4) Querying datasets, visualizing query results and creating reports'],)","(['This one-week accelerated on-demand course provides participants a a hands-on introduction to designing and building machine learning models on Google Cloud Platform. Through a combination of presentations, demos, and hand-on labs, participants will learn machine learning (ML) and TensorFlow concepts, and develop hands-on skills in developing, evaluating, and productionizing ML models.\n\nOBJECTIVES\n\nThis course teaches participants the following skills:\n\n  \xe2\x97\x8f Identify use cases for machine learning\n\n  \xe2\x97\x8f Build an ML model using TensorFlow\n\n  \xe2\x97\x8f Build scalable, deployable ML models using Cloud ML\n\n  \xe2\x97\x8f Know the importance of preprocessing and combining features\n\n  \xe2\x97\x8f Incorporate advanced ML concepts into their models\n\n  \xe2\x97\x8f Productionize trained ML models\n\n\nPREREQUISITES\n\nTo get the most of out of this course, participants should have:\n\n  \xe2\x97\x8f Completed Google Cloud Fundamentals- Big Data and Machine Learning course OR have equivalent experience\n\n  \xe2\x97\x8f Basic proficiency with common query language such as SQL\n\n  \xe2\x97\x8f Experience with data modeling, extract, transform, load activities\n\n  \xe2\x97\x8f Developing applications using a common programming language such Python\n\n  \xe2\x97\x8f Familiarity with Machine Learning and/or statistics\n\nNotes:\n\xe2\x80\xa2 You\'ll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n\xe2\x80\xa2 There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as ""business"" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n\xe2\x80\xa2 More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/'],)","(['English'],)","(['Google Cloud'],)","(['Serverless Machine Learning with Tensorflow on Google Cloud Platform'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/21/86d4304fa211e7be3013defd1eb386/Serverless_ML_Header.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Graded Quiz #1', 'Graded Quiz #2', 'Graded Quiz #3', 'Graded Quiz #4'],)",https://www.coursera.org/learn/serverless-machine-learning-gcp,313,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Intermediate', '1 week of study, 8-12 hours/week', ""You'll need a Google Cloud Platform Free Trial account. Sign up at: https://cloud.google.com/free/"", 'Pass all graded assignments to complete the course.'],)","(['3 videos', ', ', '1 practice quiz', '24 videos', ', ', '1 reading', '14 videos', ', ', '3 readings', '5 videos', ', ', '1 reading', '13 videos', ', ', '1 reading'],)","(['Welcome to Serverless Machine Learning on Google Cloud Platform', 'Module 1: Getting Started with Machine Learning', 'Module 2: Building ML models with Tensorflow', 'Module 3: Scaling ML models with Cloud ML Engine', 'Module 4: Feature Engineering'],)"
"(['Regression is one of the most important and broadly used machine learning and statistics tools out there.  It allows you to make predictions from data by learning the relationship between features of your data and some observed, continuous-valued response.  Regression is used in a massive number of applications ranging from predicting stock prices to understanding gene regulatory networks.<p>This introduction to the course provides you with an overview of the topics we will cover and the background knowledge and resources we assume you have.', 'Our course starts from the most basic regression model: Just fitting a line to data.  This simple model for forming predictions from a single, univariate feature of the data is appropriately called ""simple linear regression"".<p> In this module, we describe the high-level regression task and then specialize these concepts to the simple linear regression case. You will learn how to formulate a simple regression model and fit the model to data using both a closed-form solution as well as an iterative optimization algorithm called gradient descent.  Based on this fitted function, you will interpret the estimated model parameters and form predictions.  You will also analyze the sensitivity of your fit to outlying observations.<p> You will examine all of these concepts in the context of a case study of predicting house prices from the square feet of the house.', 'The next step in moving beyond simple linear regression is to consider ""multiple regression"" where multiple features of the data are used to form predictions.  <p> More specifically, in this module, you will learn how to build models of more complex relationship between a single variable (e.g., \'square feet\') and the observed response (like \'house sales price\').  This includes things like fitting a polynomial to your data, or capturing seasonal changes in the response value.  You will also learn how to incorporate multiple input variables (e.g., \'square feet\', \'# bedrooms\', \'# bathrooms\').  You will then be able to describe how all of these models can still be cast within the linear regression framework, but now using multiple ""features"".   Within this multiple regression framework, you will fit models to data, interpret estimated coefficients, and form predictions. <p>Here, you will also implement a gradient descent algorithm for fitting a multiple regression model.', 'Having learned about linear regression models and algorithms for estimating the parameters of such models, you are now ready to assess how well your considered method should perform in predicting new data.  You are also ready to select amongst possible models to choose the best performing.  <p> This module is all about these important topics of model selection and assessment.  You will examine both theoretical and practical aspects of such analyses. You will first explore the concept of measuring the ""loss"" of your predictions, and use this to define training, test, and generalization error.  For these measures of error, you will analyze how they vary with model complexity and how they might be utilized to form a valid assessment of predictive performance.  This leads directly to an important conversation about the bias-variance tradeoff, which is fundamental to machine learning.  Finally, you will devise a method to first select amongst models and then assess the performance of the selected model. <p>The concepts described in this module are key to all machine learning problems, well-beyond the regression setting addressed in this course.', 'You have examined how the performance of a model varies with increasing model complexity, and can describe the potential pitfall of complex models becoming overfit to the training data.   In this module, you will explore a very simple, but extremely effective technique for automatically coping with this issue.  This method is called ""ridge regression"".  You start out with a complex model, but now fit the model in a manner that not only incorporates a measure of fit to the training data, but also a term that biases the solution away from overfitted functions.  To this end, you will explore symptoms of overfitted functions and use this to define a quantitative measure to use in your revised optimization objective.  You will derive both a closed-form and gradient descent algorithm for fitting the ridge regression objective; these forms are small modifications from the original algorithms you derived for multiple regression.  To select the strength of the bias away from overfitting, you will explore a general-purpose method called ""cross validation"". <p>You will implement both cross-validation and gradient descent to fit a ridge regression model and select the regularization constant.', 'A fundamental machine learning task is to select amongst a set of features to include in a model.  In this module, you will explore this idea in the context of multiple regression, and describe how such feature selection is important for both interpretability and efficiency of forming predictions. <p> To start, you will examine methods that search over an enumeration of models including different subsets of features.  You will analyze both exhaustive search and greedy algorithms.  Then, instead of an explicit enumeration, we turn to Lasso regression, which implicitly performs feature selection in a manner akin to ridge regression: A complex model is fit based on a measure of fit to the training data plus a measure of overfitting different than that used in ridge.  This lasso method has had impact in numerous applied domains, and the ideas behind the method have fundamentally changed machine learning and statistics. You will also implement a coordinate descent algorithm for fitting a Lasso model. <p>Coordinate descent is another, general, optimization technique, which is useful in many areas of machine learning. ', 'Up to this point, we have focused on methods that fit parametric functions---like polynomials and hyperplanes---to the entire dataset.  In this module, we instead turn our attention to a class of ""nonparametric"" methods.  These methods allow the complexity of the model to increase as more data are observed, and result in fits that adapt locally to the observations.  <p> We start by considering the simple and intuitive example of nonparametric methods, nearest neighbor regression: The prediction for a query point is based on the outputs of the most related observations in the training set.  This approach is extremely simple, but can provide excellent predictions, especially for large datasets. You will deploy algorithms to search for the nearest neighbors and form predictions based on the discovered neighbors.  Building on this idea, we turn to kernel regression.  Instead of forming predictions based on a small set of neighboring observations, kernel regression uses all observations in the dataset, but the impact of these observations on the predicted value is weighted by their similarity to the query point.  You will analyze the theoretical performance of these methods in the limit of infinite training data, and explore the scenarios in which these methods work well versus struggle.  You will also implement these techniques and observe their practical behavior.', ""In the conclusion of the course, we will recap what we have covered.  This represents both techniques specific to regression, as well as foundational machine learning concepts that will appear throughout the specialization.  We also briefly discuss some important regression techniques we did not cover in this course.<p> We conclude with an overview of what's in store for you in the rest of the specialization.  ""],)","([],)","(['Case Study - Predicting Housing Prices\n\nIn our first case study, predicting house prices, you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms,...).  This is just one of the many places where regression can be applied.  Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression.\n\nIn this course, you will explore regularized linear regression models for the task of prediction and feature selection.  You will be able to handle very large sets of features and select between models of various complexity.  You will also analyze the impact of aspects of your data -- such as outliers -- on your selected models and predictions.  To fit these models, you will implement optimization algorithms that scale to large datasets.\n\nLearning Outcomes:  By the end of this course, you will be able to:\n   -Describe the input and output of a regression model.\n   -Compare and contrast bias and variance when modeling data.\n   -Estimate model parameters using optimization algorithms.\n   -Tune parameters with cross validation.\n   -Analyze the performance of the model.\n   -Describe the notion of sparsity and how LASSO leads to sparse solutions.\n   -Deploy methods to select between models.\n   -Exploit the model to form predictions. \n   -Build a regression model to predict prices using a housing dataset.\n   -Implement these techniques in Python.'],)","(['English'],)","(['University of Washington'],)","(['Machine Learning: Regression'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/ce/a819904d0011e5831033199a566ffe/gears-818461_1280.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Emily Fox', 'Carlos Guestrin'],)","(['Simple Linear Regression', 'Fitting a simple linear regression model on housing data', 'Multiple Regression', 'Exploring different multiple regression models for house price prediction', 'Implementing gradient descent for multiple regression', 'Assessing Performance', 'Exploring the bias-variance tradeoff', 'Ridge Regression', 'Observing effects of L2 penalty in polynomial regression', 'Implementing ridge regression via gradient descent', 'Feature Selection and Lasso', 'Using LASSO to select features', 'Implementing LASSO using coordinate descent', 'Nearest Neighbors & Kernel Regression', 'Predicting house prices using k-nearest neighbors regression'],)",https://www.coursera.org/learn/ml-regression,"3,196","(['Rated 4.8 out of 5 of ', ' ratings'],)","(['6 weeks of study, 5-8 hours/week', 'Pass all graded assignments to complete the course.'],)","(['5 videos', ', ', '2 readings', '25 videos', ', ', '5 readings', '19 videos', ', ', '5 readings', '14 videos', ', ', '2 readings', '16 videos', ', ', '5 readings', '22 videos', ', ', '4 readings', '13 videos', ', ', '2 readings', '5 videos', ', ', '1 reading'],)","(['Welcome', 'Simple Linear Regression', 'Multiple Regression', 'Assessing Performance', 'Ridge Regression', 'Feature Selection & Lasso', 'Nearest Neighbors & Kernel Regression', 'Closing Remarks'],)"
"(['In this session, you will learn about decision trees, a type of data mining algorithm that can select from among a large number of variables those and their interactions that are most important in predicting the target or response variable to be explained. Decision trees create segmentations or subgroups in the data, by applying a series of simple rules or criteria over and over again, which choose variable constellations that best predict the target variable.', 'In this session, you will learn about random forests, a type of data mining algorithm that can select from among a large number of variables those that are most important in determining the target or response variable to be explained. Unlike decision trees, the results of random forests generalize well to new data.', 'Lasso regression analysis is a shrinkage and variable selection method for linear regression models. The goal of lasso regression is to obtain the subset of predictors that minimizes prediction error for a quantitative response variable. The lasso does this by imposing a constraint on the model parameters that causes regression coefficients for some variables to shrink toward zero. Variables with a regression coefficient equal to zero after the shrinkage process are excluded from the model. Variables with non-zero regression coefficients variables are most strongly associated with the response variable. Explanatory variables can be either quantitative, categorical or both. In this session, you will apply and interpret a lasso regression analysis. You will also develop experience using k-fold cross validation to select the best fitting model and obtain a more accurate estimate of your model s test error rate. \nTo test a lasso regression model, you will need to identify a quantitative response variable from your data set if you haven t already done so, and choose a few additional quantitative and categorical predictor (i.e. explanatory) variables to develop a larger pool of predictors.  Having a larger pool of predictors to test will maximize your experience with lasso regression analysis. Remember that lasso regression is a machine learning method, so your choice of additional predictors does not necessarily need to depend on a research hypothesis or theory. Take some chances, and try some new variables. The lasso regression analysis will help you determine which of your predictors are most important. Note also that if you are working with a relatively small data set, you do not need to split your data into training and test data sets. The cross-validation method you apply is designed to eliminate the need to split your data when you have a limited number of observations. ', 'Cluster analysis is an unsupervised machine learning method that partitions the observations in a data set into a smaller set of clusters where each observation belongs to only one cluster. The goal of cluster analysis is to group, or cluster, observations into subsets based on their similarity of responses on multiple variables. Clustering variables should be primarily quantitative variables, but binary variables may also be included. In this session, we will show you how to use k-means cluster analysis to identify clusters of observations in your data set. You will gain experience in interpreting cluster analysis results by using graphing methods to help you determine the number of clusters to interpret, and examining clustering variable means to evaluate the cluster profiles. Finally, you will get the opportunity to validate your cluster solution by examining differences between clusters on a variable not included in your cluster analysis.  \nYou can use the same variables that you have used in past weeks as clustering variables. If most or all of your previous explanatory variables are categorical, you should identify some additional quantitative clustering variables from your data set. Ideally, most of your clustering variables will be quantitative, although you may also include some binary variables. In addition, you will need to identify a quantitative or binary response variable from your data set that you will not include in your cluster analysis. You will use this variable to validate your clusters by evaluating whether your clusters differ significantly on this response variable using statistical methods, such as analysis of variance or chi-square analysis, which you learned about in Course 2 of the specialization (Data Analysis Tools). Note also that if you are working with a relatively small data set, you do not need to split your data into training and test data sets. \n'],)","([],)","(['Are you interested in predicting future outcomes using your data? This course helps you do just that! Machine learning is the process of developing, testing, and applying predictive algorithms to achieve this goal. Make sure to familiarize yourself with course 3 of this specialization before diving into these machine learning concepts. Building on Course 3, which introduces students to integral supervised machine learning concepts, this course will provide an overview of many additional concepts, techniques, and algorithms in machine learning, from basic classification to decision trees and clustering. By completing this course, you will learn how to apply, test, and interpret machine learning algorithms as alternative methods for addressing your research questions.'],)","(['English'],)","(['Wesleyan University'],)","(['Machine Learning for Data Analysis'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/5d/58ff4036f111e589be778d9d098112/big-dataG.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Jen Rose', 'Lisa Dierker'],)","(['Running a Classification Tree', 'Running a Random Forest', 'Running a Lasso Regression Analysis', 'Running a k-means Cluster Analysis'],)",https://www.coursera.org/learn/machine-learning-data-analysis,159,"(['Rated 4.1 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['7 videos', ', ', '15 readings', '4 videos', ', ', '4 readings', '5 videos', ', ', '3 readings', '6 videos', ', ', '3 readings'],)","(['Decision Trees', 'Random Forests', 'Lasso Regression', 'K-Means Cluster Analysis'],)"
"([],)","(['This course is aimed to everybody, who feel interest in Big Data and Machine Learning. \nThe following is a desirable, but not essential:\n- Python\n- Machine Learning basics\n- Experience with Spark\n- Calculus 101\n- Theory of probability 101'],)","(['Machine learning is transforming the world around us. To become successful, you\xe2\x80\x99d better know what kinds of problems can be solved with machine learning, and how they can be solved. Don\xe2\x80\x99t know where to start? The answer is one button away.\n \nDuring this course you will:\n- Identify practical problems which can be solved with machine learning\n- Build, tune and apply linear models with Spark MLLib\n- Understand methods of text processing\n- Fit decision trees and boost them with ensemble learning\n- Construct your own recommender system.\n \nAs a practical assignment, you will \n- build and apply linear models for classification and regression tasks; \n- learn how to work with texts; \n- automatically construct decision trees and improve their performance with ensemble learning; \n- finally, you will build your own recommender system!\n\nWith these skills, you will be able to tackle many practical machine learning tasks.\n \nWe provide the tools, you choose the place of application to make this world of machines more intelligent.\n\nSpecial thanks to:\n- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.\n- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching  MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.\n- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.\n- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.'],)","(['English'],)","(['Yandex'],)","(['Big Data Applications: Machine Learning at Scale'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/5b/7d7220a14611e7bcc3e5d73bb99b6b/Yandex-466_1.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Vladimir Lesnichenko', 'Pavel Mezentsev ', 'Emeli Dral ', 'Alexey A. Dral', 'Ilya Trofimov', 'Evgeny Frolov'],)","(['Spark MLLib and Linear Models', 'Machine Learning with Texts & Feature Engineering', 'Decision Trees & Ensemble Learning', 'Predict the tree cover type using Random Forest', 'Recommender Systems', 'Recommender Systems. Spark Assignment'],)",https://www.coursera.org/learn/machine-learning-applications-big-data,3,"(['Rated 3.7 out of 5 of ', ' ratings'],)","(['Advanced', '5 weeks of study, 6-8 hours/week', 'Windows, MacOS, Linux (Ubuntu/Debian/RedHat).  min-max req: 2-4 CPU, 4-8 GB RAM, 20-50 GB disk space', 'Pass all graded assignments to complete the course.'],)","(['5 videos', '6 videos', '10 videos', ', ', '1 reading', ', ', '3 practice quizzes', '12 videos', ', ', '4 practice quizzes', '13 videos', ', ', '4 practice quizzes', '15 videos', ', ', '1 reading', ', ', '3 practice quizzes', '1 reading'],)","(['Welcome', '(Optional) Machine Learning: Introduction', 'Spark MLLib and Linear Models', 'Machine Learning with Texts & Feature Engineering', 'Decision Trees & Ensemble Learning', 'Recommender Systems', 'Recommender Systems (practice week)'],)"
