weekabout,targetlearner,description,language,creator,coursename,imageurl,instructors,weekgraded,url,ratingcount,ratingstars,basicinfo,weekinfo,weekname
"(['In this module, you will be able to define SQL and discuss how SQL differs from other computer languages. You will be able to compare and contrast the roles of a database administrator and a data scientist, and explain the differences between one-to-one, one-to-many, and many-to-many relationships with databases. You will be able to use the SELECT statement and talk about some basic syntax rules. You will be able to add comments in your code and synthesize its importance.', 'In this module, you will be able to use several more new clauses and operators including WHERE, BETWEEN, IN, OR, NOT, LIKE, ORDER BY, and GROUP BY. You will be able to use the wildcard function to search for more specific or parts of records, including their advantages and disadvantages, and how best to use them. You will be able to discuss how to use basic math operators, as well as aggregate functions like AVERAGE, COUNT, MAX, MIN, and others to begin analyzing our data.', 'In this module, you will be able to discuss subqueries, including their advantages and disadvantages, and when to use them. You will be able to recall the concept of a key field and discuss how these help us link data together with JOINs. You will be able to identify and define several types of JOINs, including the Cartesian join, an inner join, left and right joins, full outer joins, and a self join. You will be able to use aliases and pre-qualifiers to make your SQL code cleaner and efficient.', ""In this module, you will be able to discuss how to modify strings by concatenating, trimming, changing the case, and using the substring function. You will be able to discuss the date and time strings specifically. You will be able to use case statements and finish this module by discussing data governance and profiling. You will also be able to apply fundamental principles when using SQL for data science. You'll be able to use tips and tricks to apply SQL in a data science context.\n""],)","(['This course is primary targeted for anyone entering the data science field. It assumes you have no prior knowledge of the SQL programming language.'],)","([""As data collection has increased exponentially, so has the need for people skilled at using and interacting with data; to be able to think critically, and provide insights to make better decisions and optimize their businesses. This is a data scientist, \xe2\x80\x9cpart mathematician, part computer scientist, and part trend spotter\xe2\x80\x9d (SAS Institute, Inc.). According to Glassdoor, being a data scientist is the best job in America; with a median base salary of $110,000 and thousands of job openings at a time. The skills necessary to be a good data scientist include being able to retrieve and work with data, and to do that you need to be well versed in SQL, the standard language for communicating with database systems.\n\nThis course is designed to give you a primer in the fundamentals of SQL and working with data so that you can begin analyzing it for data science purposes. You will begin to ask the right questions and come up with good answers to deliver valuable insights for your organization. This course starts with the basics and assumes you do not have any knowledge or skills in SQL. It will build on that foundation and gradually have you write both simple and complex queries to help you select data from tables.  You'll start to work with different types of data like strings and numbers and discuss methods to filter and pare down your results. \n\nYou will create new tables and be able to move data into them. You will learn common operators and how to combine the data. You will use case statements and concepts like data governance and profiling. You will discuss topics on data, and practice using real-world programming assignments. You will interpret the structure, meaning, and relationships in source data and use SQL as a professional to shape your data for targeted analysis purposes. \n\nAlthough we do not have any specific prerequisites or software requirements to take this course, you a simple text editor is recommended for the final project. So what are you waiting for? This is your first step in landing a job in the best occupation in the US and soon the world!""],)","(['English'],)","(['University of California, Davis'],)","(['SQL for Data Science'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/85/285700aab711e78a673dcad995cb92/1200px-132px.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Sadie St. Lawrence'],)","(['Module 1 Quiz', 'Module 1 Coding Questions', 'Module 2 Quiz', 'Module 2 Coding Assignment', 'Module 3 Quiz', 'Module 3 Coding Assignment', 'Module 4 Quiz', 'Module 4 Coding Questions', 'Data Scientist Role Play: Profiling and Analyzing the Yelp Dataset'],)",https://www.coursera.org/learn/sql-for-data-science,39,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['Beginner', '4 weeks of study, 3-5 hours/week', 'Pass all graded assignments to complete the course.'],)","(['11 videos', ', ', '2 readings', '9 videos', ', ', '1 reading', '10 videos', ', ', '2 readings', '10 videos', ', ', '2 readings'],)","(['Getting Started and Selecting & Retrieving Data with SQL', 'Filtering, Sorting, and Calculating Data with SQL', 'Subqueries and Joins in SQL', 'Modifying and Analyzing Data with SQL'],)"
"([],)","([],)","(['In this final course you will complete a Capstone Project using data analysis to recommend a method for improving profits for your company, Watershed Property Management, Inc. Watershed is responsible for managing thousands of residential rental properties throughout the United States. Your job is to persuade Watershed\xe2\x80\x99s management team to pursue a new strategy for managing its properties that will increase their profits. To do this, you will: (1) Elicit information about important variables relevant to your analysis; (2) Draw upon your new MySQL database skills to extract relevant data from a real estate database; (3) Implement data analysis in Excel to identify the best opportunities for Watershed to increase revenue and maximize profits, while managing any new risks; (4) Create a Tableau dashboard to show Watershed executives the results of a sensitivity analysis; and (5) Articulate a significant and innovative business process change for Watershed based on your data analysis, that you will recommend to company executives. \n\nAirbnb, our Capstone\xe2\x80\x99s official Sponsor, provided input on the project design. The top 10 Capstone completers each year will have the opportunity to present their work directly to senior data scientists at Airbnb live for feedback and discussion.\n\n""Note: Only learners who have passed the four previous courses in the specialization are eligible to take the Capstone.""'],)","(['English'],)","(['Duke University'],)","(['Increasing Real Estate Management Profits: Harnessing Data Analytics'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/fd/9a25603cf511e59cda870bd1fe5fe5/CourseraIcons.Square1200.5.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Daniel Egger', 'Jana Schaich Borg'],)","(['Your Three Elicitation Interviews', 'Elicitation', 'Verify You Have Extracted the Correct Data', 'Make Sure You Understand What Your Data Mean', 'First Best-Fit Line', 'Normalization', 'Applying Normalization to the Comparable Properties', 'Optimization Basics', 'Optimizing Watershed Rents', 'Alternative to Solver', 'Profitability', 'Cash Flow Risk and Total Cash Required', 'Sensitivity Analysis: Measuring Cutoffs at 40% Transaction Fee', 'Sensitivity Analysis', 'A Very Important Question!', 'Final Project Assignment Submission'],)",https://www.coursera.org/learn/analytics-capstone,93,"(['Rated 4.7 out of 5 of ', ' ratings'],)","(['8 weeks of study, 8-10 hours/week', 'Pass all graded assignments to complete the course.'],)","(['5 videos', ', ', '14 readings', '1 video', ', ', '3 readings', '5 videos', ', ', '16 readings', '3 videos', ', ', '11 readings', '6 videos', ', ', '3 readings', '2 videos', ', ', '6 readings', '2 videos', ', ', '7 readings'],)","(['Introduction', 'Data Extraction and Visualization', 'Modeling', 'Cash Flow and Profits', 'Data Dashboard', 'Dashboard for Decision-makers', 'Final Project'],)"
"([],)","(['This course is aimed to everybody, who feel interest in Big Data. As the technologies covered throughout the course operate in Unix environment, we expect you to have basic understanding of the subject. Things like processes and files assumed to be familiar for the learner. Python is required to complete programming assignments.'],)","(['No doubt working with huge data volumes is hard, but to move a mountain, you have to deal with a lot of small stones. But why strain yourself? Using  Mapreduce and Spark you tackle the issue partially, thus leaving some space for high-level tools. Stop  struggling to make your big data workflow productive and efficient,  make use of the tools we are offering you.\n \nThis course will teach you how to:\n- Warehouse your data efficiently using Hive, Spark SQL and Spark DataFframes. \n- Work with large graphs, such as social graphs or networks. \n- Optimize your Spark applications for maximum performance.\n\nPrecisely, you will master your knowledge in:\n- Writing and executing Hive & Spark SQL queries;\n- Reasoning how the queries are translated into actual execution primitives (be it MapReduce jobs or Spark transformations);\n- Organizing your data in Hive to optimize disk space usage and execution times;\n- Constructing Spark DataFrames and using them to write ad-hoc analytical jobs easily;\n- Processing large graphs with Spark GraphFrames;\n- Debugging, profiling and optimizing Spark application performance.\n \nStill in doubt? Check this out. Become a data ninja by taking this course!\n\nSpecial thanks to:\n- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.\n- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching  MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.\n- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.\n- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.'],)","(['English'],)","(['Yandex'],)","(['Big Data Analysis: Hive, Spark SQL, DataFrames and GraphFrames'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/4d/139d80a15611e7a43d47ca6b50b400/Yandex-466_3.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Natalia Pritykovskaya', 'Pavel Klemenkov', 'Pavel Mezentsev ', 'Alexey A. Dral'],)","(['Hive final', 'Demo Assignment', 'Hive assignment. Task1', 'Hive assignment. Task2', 'Hive assignment. Task3', 'Spark SQL and Spark Dataframe', 'Graph Analysis from Big Data Perspective', 'Counting number of the mutual friends', 'PageRank and Recent Advances', 'Graph based Music Recommender. Task 1', 'Graph based Music Recommender. Task 2', 'Graph based Music Recommender. Task 3', 'Graph based Music Recommender. Task 4', 'Graph based Music Recommender. Task 5', 'Graph based Music Recommender. Task 6', 'Final Quiz', 'Breadth-first search in Spark SQL'],)",https://www.coursera.org/learn/big-data-analysis,7,"(['Rated 3.9 out of 5 of ', ' ratings'],)","(['Advanced', '6 weeks of study, 6-8 hours/week', 'Windows, MacOS, Linux (Ubuntu/Debian/RedHat).  min-max req: 2-4 CPU, 4-8 GB RAM, 20-50 GB disk space', 'Pass all graded assignments to complete the course.'],)","(['8 videos', '15 videos', ', ', '2 readings', ', ', '2 practice quizzes', '1 video', ', ', '2 readings', '14 videos', ', ', '1 practice quiz', '13 videos', ', ', '3 practice quizzes', '10 videos', ', ', '1 reading', ', ', '3 practice quizzes', '17 videos', ', ', '1 reading', ', ', '3 practice quizzes'],)","(['Welcome to the Second Course: Big Data Analysis', 'Big Data SQL: Hive', 'Big Data SQL: Hive (practice week)', 'Spark SQL and Spark Dataframe', 'Graph Analysis from Big Data Perspective', 'PageRank and Recent Advances', 'Spark Internals and Optimization'],)"
"(['This module contains three lessons that are build to basic math vocabulary. The first lesson, ""Sets and What They re Good For,"" walks you through the basic notions of set theory, including unions, intersections, and cardinality. It also gives a real-world application to medical testing. The second lesson, ""The Infinite World of Real Numbers,"" explains notation we use to discuss intervals on the real number line. The module concludes with the third lesson, ""That Jagged S Symbol,"" where you will learn how to compactly express a long series of additions and use this skill to define statistical quantities like mean and variance.', 'This module builds vocabulary for graphing functions in the plane. In the first lesson, ""Descartes Was Really Smart,"" you will get to know the Cartesian Plane, measure distance in it, and find the equations of lines. The second lesson introduces the idea of a function as an input-output machine, shows you how to graph functions in the Cartesian Plane, and goes over important vocabulary.', 'This module begins a very gentle introduction to the calculus concept of the derivative.  The first lesson, ""This is About the Derivative Stuff,"" will give basic definitions, work a few examples, and show you how to apply these concepts to the real-world problem of optimization. We then turn to exponents and logarithms, and explain the rules and notation for these math tools. Finally we learn about the rate of change of continuous growth, and the special constant known as \xe2\x80\x9ce\xe2\x80\x9d that captures this concept in a single number\xe2\x80\x94near 2.718.', 'This module introduces the vocabulary and notation of probability theory \xe2\x80\x93 mathematics for the study of outcomes that are uncertain but have predictable rates of occurrence. \n\nWe start with the basic definitions and rules of probability, including the probability of two or more events both occurring, the sum rule and the product rule, and then proceed to Bayes  Theorem and how it is used in practical problems.'],)","(['This course is for anyone who has basic math skills, but is interested in learning or relearning algebra or pre-calculus so they can be successful in other data science math courses.   '],)","(['Data science courses contain math\xe2\x80\x94no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time. \n\nLearners who complete this course will master the vocabulary, notation, concepts, and algebra rules that all data scientists must know before moving on to more advanced material.\n\nTopics include:\n~Set theory, including Venn diagrams\n~Properties of the real number line\n~Interval notation and algebra with inequalities\n~Uses for summation and Sigma notation\n~Math on the Cartesian (x,y) plane, slope and distance formulas\n~Graphing and describing functions and their inverses on the x-y plane,\n~The concept of instantaneous rate of change and tangent lines to a curve\n~Exponents, logarithms, and the natural log function.\n~Probability theory, including Bayes\xe2\x80\x99 theorem.\n\nWhile this course is intended as a general introduction to the math skills needed for data science, it can be considered a prerequisite for learners interested in the course, ""Mastering Data Analysis in Excel,"" which is part of the Excel to MySQL Data Science Specialization.  Learners who master Data Science Math Skills will be fully prepared for success with the more advanced math concepts introduced in ""Mastering Data Analysis in Excel."" \n\nGood luck and we hope you enjoy the course!'],)","(['English'],)","(['Duke University'],)","(['Data Science Math Skills'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/08/8c6610c07e11e6a7f5e70b413367a6/DMSIcon.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Daniel Egger', 'Paul Bendich'],)","(['Graded quiz on Sets, Number Line, Inequalities, Simplification, and Sigma Notation', 'Graded quiz on Cartesian Plane and Types of Function', 'Graded quiz on Tangent Lines to Functions, Exponents and Logarithms', 'Probability (basic and Intermediate)\xc2\xa0Graded Quiz'],)",https://www.coursera.org/learn/datasciencemathskills,774,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Beginner', 'Four weeks, 3-5 hours per week.', 'Pass all graded assignments to complete the course.'],)","(['1 video', ', ', '2 readings', '10 videos', ', ', '4 readings', ', ', '3 practice quizzes', '8 videos', ', ', '3 readings', ', ', '2 practice quizzes', '7 videos', ', ', '3 readings', ', ', '2 practice quizzes', '8 videos', ', ', '4 readings', ', ', '3 practice quizzes'],)","(['Welcome to Data Science Math Skills', 'Building Blocks for Problem Solving', 'Functions and Graphs', 'Measuring Rates of Change', 'Introduction to Probability Theory'],)"
"([],)","(['This is course is primarily aimed at new Data  Analysts,  Business  Analysts, and Business  Intelligence  professionals. It is also intended for Cloud  Data  Engineers  who  will  be partnering  with  Data  Analysts  to  build scalable  data  solutions  on  Google Cloud  Platform.\n\nNote that this first course has a module on SQL basics that will be serve as a review for those already familiar with the language.'],)","(['Welcome to the Coursera specialization, From Data to Insights with Google Cloud Platform brought to you by the Google Cloud team. I\xe2\x80\x99m Evan Jones (a data enthusiast) and I\xe2\x80\x99m going to be your guide.\n\nThis first course in this specialization is Exploring and Preparing your Data. Here we will see what the common challenges faced by data analysts are and how to solve them with the big data tools on Google Cloud Platform. You\xe2\x80\x99ll pick up some SQL along the way and become very familiar with using BigQuery and Cloud Dataprep to analyze and transform your datasets.'],)","(['English'],)","(['Google Cloud'],)","(['Exploring  and  Preparing  your  Data with BigQuery'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/04/d725c0bd3311e797d69d8eb3c0ee4d/header-2.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Module 1 Quiz', 'Module 2 Quiz', 'Module 3 Quiz', 'Module 4 Quiz', 'Module 5 Quiz'],)",https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,43,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Beginner', '1 week of study, 5-7 hours/week', ""You'll need a desktop web browser to run this course's interactive labs via Qwiklabs."", 'Pass all graded assignments to complete the course.'],)","(['1 video', '6 videos', '7 videos', '10 videos', '8 videos', '9 videos'],)","(['Welcome to From  Data  to  Insights  with  Google  Cloud Platform:  Exploring  and  Preparing  your  Data', 'Module 1: Introduction  to  Data  on Google  Cloud  Platform', 'Module 2:  Big  Data  Tools  Overview', 'Module 3:  Exploring  your  Data  with SQL', 'Module 4:  Google  BigQuery  Pricing', 'Module 5:  Cleaning  and  Transforming your  Data'],)"
"(['This module introduces the idea of computational thinking, and how big data can make simple problems quite challenging to solve. We use the example of calculating the median and mean stack of a set of radio astronomy images to illustrate some of the issues you encounter when working with large datasets. ', 'In this module we explore the idea of scaling your code. Some algorithms scale well as your dataset increases, but others become impossibly slow. We look at some of the reason for this, and use the example of cross-matching astronomical catalogues to demonstrate what kind of improvements you can make. ', 'Most large astronomy projects use databases to manage their data. In this module we introduce SQL - the language most commonly used to query databases. We use SQL to query the NASA Exoplanet database and investigate the habitability of planets in other solar systems.'],)","(['This course is aimed at science students with an interest in computational approaches to problem solving, people with an interest in astronomy who would like to learn current research methods, or people who would like to improve their programming by applying it to astronomy examples. '],)","(['Science is undergoing a data explosion, and astronomy is leading the way. Modern telescopes produce terabytes of data per observation, and the simulations required to model our observable Universe push supercomputers to their limits. To analyse this data scientists need to be able to think computationally to solve problems. In this course you will investigate the challenges of working with large datasets: how to implement algorithms that work; how to use databases to manage your data; and how to learn from your data with machine learning tools. The focus is on practical skills - all the activities will be done in Python 3, a modern programming language used throughout astronomy.\n\nRegardless of whether you\xe2\x80\x99re already a scientist, studying to become one, or just interested in how modern astronomy works \xe2\x80\x98under the bonnet\xe2\x80\x99, this course will help you explore astronomy: from planets, to pulsars to black holes.\n\nCourse outline:\nWeek 1: Thinking about data\n- Principles of computational thinking\n- Discovering pulsars in radio images\n\nWeek 2: Big data makes things slow\n- How to work out the time complexity of algorithms\n- Exploring the black holes at the centres of massive galaxies\n\nWeek 3: Querying data using SQL\n- How to use databases to analyse your data\n- Investigating exoplanets in other solar systems\n\nWeek 4: Managing your data\n- How to set up databases to manage your data\n- Exploring the lifecycle of stars in our Galaxy\n\nWeek 5: Learning from data: regression\n- Using machine learning tools to investigate your data\n- Calculating the redshifts of distant galaxies\n\nWeek 6: Learning from data: classification\n- Using machine learning tools to classify your data\n- Investigating different types of galaxies\n\nEach week will also have an interview with a data-driven astronomy expert.\n\nNote that some knowledge of Python is assumed, including variables, control structures, data structures, functions, and working with files.'],)","(['English'],)","(['The University of Sydney'],)","(['Data-driven Astronomy'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0f/79d550ed5311e68a91457769e062c8/banner4.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Tara Murphy', 'Simon Murphy'],)","(['Set up your online assessment', 'Pulsars: test your understanding', 'Calculating the mean stack', 'Supermassive black holes: test your understanding', 'A naive cross-matcher', 'Exoplanets - test your understanding', 'Writing your own SQL queries', 'Stars - test your understanding', 'Setting up your own database', 'Cosmological distances - test your understanding', 'Building a regression classifier', 'Galaxies - test your understanding', 'Exploring machine learning classification'],)",https://www.coursera.org/learn/data-driven-astronomy,136,"(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Intermediate', '6 weeks of study, 4-6 hours/week', ""You'll need to have a computer with internet access."", 'Pass all graded assignments to complete the course.'],)","(['8 videos', ', ', '1 reading', '7 videos', '7 videos', '6 videos', '7 videos', '7 videos', ', ', '1 reading'],)","(['Thinking about data', 'Big data makes things slow', 'Querying your data', 'Managing your data', 'Learning from data: regression', 'Learning from data: classification'],)"
"(['Understand the terminology and recurring principles associated with data science, and understand the structure of data science projects and emerging methodologies to approach them.    Why does this emerging field exist?  How does it relate to other fields?  How does this course distinguish itself?  What do data science projects look like, and how should they be approached?  What are some examples of data science projects?  ', 'Relational Databases are the workhouse of large-scale data management.  Although originally motivated by problems in enterprise operations, they have proven remarkably capable for analytics as well.  But most importantly, the principles underlying relational databases are universal in managing, manipulating, and analyzing data at scale.  Even as the landscape of large-scale data systems has expanded dramatically in the last decade, relational models and languages have remained a unifying concept.  For working with large-scale data, there is no more important programming model to learn.', 'NoSQL systems are purely about scale rather than analytics, and are arguably less relevant for the practicing data scientist.  However, they occupy an important place in many practical big data platform architectures, and data scientists need to understand their limitations and strengths to use them effectively.', 'Graph-structured data are increasingly common in data science contexts due to their ubiquity in modeling the communication between entities: people (social networks), computers (Internet communication), cities and countries (transportation networks), or corporations (financial transactions).  Learn the common algorithms for extracting information from graph data and how to scale them up. '],)","([],)","(['Data analysis has replaced data acquisition as the bottleneck to evidence-based decision making --- we are drowning in it.  Extracting knowledge from large, heterogeneous, and noisy datasets requires not only powerful computing resources, but the programming abstractions to use them effectively.  The abstractions that emerged in the last decade blend ideas from parallel databases, distributed systems, and programming languages to create a new class of scalable data analytics platforms that form the foundation for data science at realistic scales.\n\nIn this course, you will learn the landscape of relevant systems, the principles on which they rely, their tradeoffs, and how to evaluate their utility against your requirements. You will learn how practical systems were derived from the frontier of research in computer science and what systems are coming on the horizon.   Cloud computing, SQL and NoSQL databases, MapReduce and the ecosystem it spawned, Spark and its contemporaries, and specialized systems for graphs and arrays will be covered.\n\nYou will also learn the history and context of data science, the skills, challenges, and methodologies the term implies, and how to structure a data science project.  At the end of this course, you will be able to:\n\nLearning Goals: \n1. Describe common patterns, challenges, and approaches associated with data science projects, and what makes them different from projects in related fields.\n2. Identify and use the programming models associated with scalable data manipulation, including relational algebra, mapreduce, and other data flow models.\n3. Use database technology adapted for large-scale analytics, including the concepts driving parallel databases, parallel query processing, and in-database analytics\n4. Evaluate key-value stores and NoSQL systems, describe their tradeoffs with comparable systems, the details of important examples in the space, and future trends.\n5. \xe2\x80\x9cThink\xe2\x80\x9d in MapReduce to effectively write algorithms for systems including Hadoop and Spark.  You will understand their limitations, design details, their relationship to databases, and their associated ecosystem of algorithms, extensions, and languages.\nwrite programs in Spark\n6. Describe the landscape of specialized Big Data systems for graphs, arrays, and streams'],)","(['English'],)","(['University of Washington'],)","(['Data Manipulation at Scale: Systems and Algorithms'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera.s3.amazonaws.com/topics/datasci/large-icon.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Bill Howe'],)","(['Twitter Sentiment Analysis', 'SQL for Data Science Assignment', 'Thinking in MapReduce'],)",https://www.coursera.org/learn/data-manipulation,611,"(['Rated 4.3 out of 5 of ', ' ratings'],)","(['4 weeks of study, 6-8 hours/week', 'Pass all graded assignments to complete the course.'],)","(['22 videos', ', ', '4 readings', '24 videos', '26 videos', '36 videos', '21 videos'],)","(['Data Science Context and Concepts', 'Relational Databases and the Relational Algebra', 'MapReduce and Parallel Dataflow Programming', 'NoSQL: Systems and Concepts', 'Graph Analytics'],)"
"(['Module 1 provides the context for Database Management Essentials. When you re done, you ll understand the objectives for the course and know what topics and assignments to expect. Keeping these course objectives in mind will help you succeed throughout the course! You should read about the database software requirements in the last lesson of module 1. I recommend that you try to install the DBMS software this week before assignments begin in week 2.', 'We ll launch into an exploration of databases and database technology and their impact on organizations in Module 2. We ll investigate database characteristics, database technology features, including non-procedural access, two key processing environments, and an evolution of the database software industry. This short informational module will ensure that we all have the same background and context, which is critical for success in the later modules that emphasize details and hands-on skills.\n', 'Now that you have the informational context for database features and environments, you ll start building! In this module, you ll learn relational data model terminology, integrity rules, and the CREATE TABLE statement. You ll apply what you ve learned in practice and graded problems using a database management system (DBMS), either Oracle or MySQL, creating tables using the SQL CREATE TABLE statement and populating your tables using given SQL INSERT statements.\n', 'This module is all about acquiring query formulation skills. Now that you know the relational data model and have basic skills with the CREATE TABLE statement, we can cover basic syntax of the SQL SELECT statement and the join operator for combining tables. SELECT statement examples are presented for single table conditions, join operations, and grouping operations. You ll practice writing simple SELECT statements using the tables that you created in the assignment for module 3.\n', 'Now that you can identify and use the SELECT statement and the join operator, you ll extend your problem solving skills in this module so you can gain confidence on more complex queries. You will work on retrieval problems with multiple tables and grouping. In addition, you ll learn to use the UNION operator in the SQL SELECT statement and write SQL modification statements.\n', 'Module 6 represents another shift in your learning. In previous modules, you ve created and populated tables and developed query formulation skills using the SQL SELECT statement. Now you ll start to develop skills that allow you to create a database design to support business requirements. You ll learn basic notation used in entity relationship diagrams (ERDs), a graphical notation for data modeling. You will create simple ERDs using basic diagram symbols and relationship variations to start developing your data modeling skills. \n', 'Module 7 builds on your knowledge of database development using basic ERD symbols and relationship variations. We ll be practicing precise usage of ERD notation and basic problem solving skills. You will learn about diagram rules and work problems to help you gain confidence using and creating ERDs.\n', 'In Module 8, you ll use your ERD notation skills and your ability to avoid diagram errors to develop ERDs that satisfy specific business data requirements. You will learn and practice powerful problem-solving skills as you analyze narrative statements and transformations to generate alternative ERDs.\n', 'Now that you have practiced data modeling techniques, you ll get to wrestle with narrative problem analyses and transformations for generating alternative database designs in Module 9. At the end of this module, you ll learn guidelines for documentation and detection of design errors that will serve you well as you design databases for business situations.\n', 'Modules 6 to 9 covered conceptual data modeling, emphasizing precise usage of ERD notation, analysis of narrative problems, and generation of alternative designs. Modules 10 and 11 cover logical database design, the next step in the database development process. In Module 10, we ll cover schema conversion, the first step in the logical database design phase. You will learn to convert an ERD into a table design that can be implemented on a relational DBMS.\n', 'Module 11 covers normalization, the second part of the logical database design process. Normalization provides tools to remove unwanted redundancy in a table design. You ll discover the motivation for normalization, constraints to reason about unwanted redundancy, and rules that detect excessive redundancy in a table design. You ll practice integrating and applying normalization techniques in the final lesson of this course.\n'],)","([],)","(['Database Management Essentials provides the foundation you need for a career in database development, data warehousing, or business intelligence, as well as for the entire Data Warehousing for Business Intelligence specialization. In this course, you will create relational databases, write SQL statements to extract information to satisfy business reporting requests, create entity relationship diagrams (ERDs) to design databases, and analyze table designs for excessive redundancy. As you develop these skills, you will use either Oracle or MySQL to execute SQL statements and a database diagramming tool such as the ER Assistant to create ERDs. We\xe2\x80\x99ve designed this course to ensure a common foundation for specialization learners. Everyone taking the course can jump right in with writing SQL statements in Oracle or MySQL.'],)","(['English'],)","(['University of Colorado System'],)","(['Database Management Essentials'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/d6/8df4a04d0911e593b04f99cfdaa374/Course-1---Logo.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Michael Mannino'],)","(['Module02 Quiz', 'Module 3 Assignment', 'Module 4 Assignment', 'Module 5 Assignment', 'Module 6 Assignment', 'Module 7 Assignment', 'Module 8 Assignment ', 'Module 9 Assignment', 'Module 10 Assignment', 'Module 11 Assignment'],)",https://www.coursera.org/learn/database-management,"1,169","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['7 weeks of study, 4-6 hours/week', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '6 readings', '7 videos', ', ', '8 readings', ', ', '1 practice quiz', '5 videos', ', ', '11 readings', ', ', '1 practice quiz', '5 videos', ', ', '11 readings', ', ', '1 practice quiz', '5 videos', ', ', '10 readings', ', ', '1 practice quiz', '4 videos', ', ', '7 readings', '5 videos', ', ', '8 readings', '4 videos', ', ', '7 readings', '3 videos', ', ', '6 readings', '3 videos', ', ', '6 readings', '6 videos', ', ', '8 readings'],)","(['Course Introduction', 'Introduction to Databases and DBMSs', 'Relational Data Model and the CREATE TABLE Statement', 'Basic Query Formulation with SQL', 'Extended Query Formulation with SQL', 'Notation for Entity Relationship Diagrams', 'ERD Rules and Problem Solving', 'Developing Business Data Models', 'Data Modeling Problems and Completion of an ERD', 'Schema Conversion', 'Normalization Concepts and Practice'],)"
"(['Welcome to week 1! In this module we ll learn how to think about analytical problems and examine the process by which data enables analysis & decision making. We ll introduce a framework called the Information-Action Value chain which describes the path from events in the world to business action, and we ll look at some of the source systems that are used to capture data. At the end of this course you will be able to: Explain the information lifecycle from events in the real world to business actions, and how to think about analytical problems in that context , Recognize the types of events and characteristics that are often used in business analytics, and explain how the data is captured by source systems and stored using both traditional and emergent technologies, Gain a high-level familiarity with relational databases and learn how to use a simple but powerful language called SQL to extract analytical data sets of interest, Appreciate the spectrum of roles involved in the data lifecycle, and gain exposure to the various ways that organizations structure analytical functions,  Summarize some of the key ideas around data quality, data governance, and data privacy', 'In this module we ll learn about the technologies that enable analytical work.  We ll examine data storage and databases, including the relational database.  We ll talk about Big Data and Cloud technologies and ideas like federation, virtualization, and in-memory computing.  We ll also walk through a landscape of some of the more common tool classes and learn how these tools support common analytical tasks.\n', 'In this module we ll learn how to extract data from a relational database using Structured Query Language, or SQL.  We ll cover all the basic SQL commands and learn how to combine and stack data from different tables.  We ll also learn how to expand the power of our queries using operators and handle additional complexity using subqueries.', 'In this module we focus on the people and organizations that work with data and actually execute analytics.  We ll discuss who does what and see how organizational structures can influence efficiency and effectiveness.  We ll also look at the supporting rules & processes that help an analytical organization run smoothly, like Data Governance, Data Privacy, and Data Quality.'],)","(['This course is designed to have broad appeal across many types of learners.  Anyone who is looking to gain an understanding of how business analytics is actually performed in real organizations will benefit.\n\nThis course is primarily aimed at professionals who have a bachelor\xe2\x80\x99s degree and/or some exposure to the business world.  Those with technical degrees or more advanced business degrees like an MBA will find certain areas easier to absorb, and may get maximum value from the course.  However, even undergraduates in non-technical fields or advanced high-school students pursuing internships will be able to follow most concepts and get value from the course.  Finally, even professionals who have had deep experiences in methods will likely find value in this course. \n'],)","(['This course will expose you to the data analytics practices executed in the business world. We will explore such key areas as the analytical process, how data is created, stored, accessed, and how the organization works with data and creates the environment in which analytics can flourish.\n\nWhat you learn in this course will give you a strong foundation in all the areas that support analytics and will help you to better position yourself for success within your organization. You\xe2\x80\x99ll develop skills and a perspective that will make you more productive faster and allow you to become a valuable asset to your organization.\n\nThis course also provides a basis for going deeper into advanced investigative and computational methods, which you have an opportunity to explore in future courses of the Data Analytics for Business specialization.'],)","(['English'],)","(['University of Colorado Boulder'],)","(['Introduction to Data Analytics for Business'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/f5/75e810715611e68c3351881cd9035c/AdobeStock_103695961-copy.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['David Torgerson'],)","(['Week 1 Quiz', 'Week 2 Quiz', 'SQL Coding Assignment', 'Week 4 Quiz', 'Final Course Assignment'],)",https://www.coursera.org/learn/data-analytics-business,168,"(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['9 videos', ', ', '3 readings', '7 videos', ', ', '3 readings', '7 videos', ', ', '3 readings', '6 videos', ', ', '2 readings'],)","(['Data and Analysis in the Real World', 'Analytical Tools', 'Data Extraction Using SQL', 'Real World Analytical Organizations'],)"
"([""To start this class out we cover the basics of Object Oriented Python. We won't be writing our own objects, but since many of the things we use like BeautifulSoup, strings, dictionaries, database connections all use Object Oriented (OO) patterns we should at least understand some of its patterns and terminology.""],)","([],)","(['This course will introduce students to the basics of the Structured Query Language (SQL) as well as basic database design for storing data as part of a multi-step data gathering, analysis, and processing effort.  The course will use SQLite3 as its database.  We will also build web crawlers and multi-step data gathering and visualization processes.  We will use the D3.js library to do basic data visualization.  This course will cover Chapters 14-15 of the book \xe2\x80\x9cPython for Everybody\xe2\x80\x9d. To succeed in this course, you should be familiar with the material covered in Chapters 1-13 of the textbook and the first three courses in this specialization. This course covers Python 3.'],)","(['English'],)","(['University of Michigan'],)","(['Using Databases with Python'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/9d/172890502911e5827cbbcae1b894c9/pythondatabases_thumbnail_1x1.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Charles Severance'],)","(['Using Encoded Data in Python 3', 'Object Oriented Programming', 'Single-Table SQL', 'Our First Database', 'Counting Email in a Database', 'Multi-Table Relational SQL', 'Multi-Table Database - Tracks', 'Many-to-Many Relationships and Python', 'Many Students in Many Courses', 'Databases and Visualization (peer-graded)'],)",https://www.coursera.org/learn/python-databases,"6,873","(['Rated 4.8 out of 5 of ', ' ratings'],)","(['5 weeks of study, 2-3 hours/week', 'Pass all graded assignments to complete the course.'],)","(['8 videos', ', ', '4 readings', '7 videos', '8 videos', '5 videos', '6 videos', ', ', '2 readings'],)","(['Object Oriented Python', 'Basic Structured Query Language', 'Data Models and Relational SQL', 'Many-to-Many Relationships in SQL', 'Databases and Visualization'],)"
"(['The Coursera Specialization, ""Managing Big Data with MySQL"" is about how \'Big Data\' interacts with business, and how to use data analytics to create value for businesses. This specialization consists of four courses and a final Capstone Project, where you will apply your skills to a real-world business process. You will learn to perform sophisticated data-analysis functions using powerful software tools such as Microsoft Excel, Tableau, and MySQL. To learn more about the specialization, please review the first lesson below, ""Specialization Introduction: Excel to MySQL: Analytic Techniques for Business.""  In this fourth course of this specialization, ""Managing Big Data with MySQL\xe2\x80\x9d you will learn how relational databases  work and how they are used in business analysis. Specifically, you will: (1) Describe the structure of relational databases; (2) Interpret and create entity-relationship diagrams and relational schemas that describe the contents of specific databases; (3) Write queries that retrieve and sort data that meet specific criteria, and retrieve such data from real MySQL and Teradata business databases that contain over 1 million rows of data; (4) Execute practices that limit the impact of your queries on other coworkers; (5) Summarize rows of data using aggregate functions, and segment aggregations according to specified variables; (6) Combine and manipulate data from multiple tables across a database; (7) Retrieve records and compute calculations that are dependent on dynamic data features; (8) Translate data analysis questions into SQL queries that accommodate the types of anomalies found in real data sets. By the end of this course, you will have a clear understanding of how relational databases work and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses.  Analysts that understand how to access this data \xe2\x80\x93 this means you! \xe2\x80\x93 will have a strong competitive advantage in this data-smitten business world.  To get started with this course, you can begin with, ""Introduction to Managing Big Data with MySQL.""  Please take some time to not only watch the videos, but also read through the course overview as there is extremely important course information in the overview.  ', ""Welcome to week 1! This week  you will learn how relational databases are organized, and practice making and interpreting Entity Relationship (ER) diagrams and relational schemas that describe the structure of data stored in a database. <p>By the end of the week, you will be able to:<ul><li>Describe the fundamental principles of relational database design <li>Interpret Entity Relationship (ER) diagrams and Entity Relationship (ER) schemas, and</li><li>Create your own ER diagrams and relational schemas using a software tool called ERDPlus that you will use to aid your query-writing later in the course.</li></ul><p>This week s exercises are donated from a well-known Database Systems textbook, and will help you deepen and strengthen your understanding of how relational databases are organized.  This deeper understanding will help you navigate complicated business databases, and allow you to write more efficient queries.  At the conclusion of the week, you will test your understanding of database design principles by completing the Week 1 graded quiz.</p> <p>To get started, please begin with the video \xe2\x80\x9cProblems with Having a Lot of Data Used by a Lot of People.\xe2\x80\x9d <p>As always, if you have any questions, post them to the Discussions. <p>I hope you enjoy this week's materials!"", ""Welcome to week 2! This week, you will start interacting with business databases. You will write SQL queries that query data from two real companies. One data set, donated from a local start-up in Durham, North Carolina called Dognition, is a MySQL database containing tables of over 1 million rows. The other data set, donated from a national US department store chain called Dillard s, is a Teradata database containing tables with over a hundred million rows. By the end of the week, you will be able to:1.  Use two different database user interfaces2.  Write queries to verify and describe all the contents of the Dognition MySQL database and the Dillard s Teradata database3.  Retrieve data that meet specific criteria in a socially-responsible using SELECT, FROM, WHERE, LIMIT, and TOP clauses, and4.  Format the data you retrieve using aliases, DISTINCT clauses, and ORDER BY clauses.Make sure to watch the instructional videos about how to use the database interfaces we have established for this course, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 2 graded quiz.To get started, please begin with the video \xe2\x80\x9cIntroduction to Week 2.\xe2\x80\x9d  As always, if you have any questions, post them to the Discussions. Enjoy this week's materials!\n"", ""<p>Welcome to week 3! This week, we are going to learn the SQL syntax that allows you to segment your data into separate categories and segment.  We are also going to learn how to combine data stored in separate tables.</p><p>By the end of the week, you will be able to:</p><ul><li>Summarize values across entire columns, and break those summaries up according to specific variables or values in others columns using GROUP BY and HAVING clauses</li><li>Combine information from multiple tables using inner and outer joins</li><li>Use strategies to manage joins between tables with duplicate rows, many-to-many relationships, and atypical configurations</li><li>Practice one of the slightly more challenging use cases of aggregation functions, and</li><li>Work with the Dognition database to learn more about how MySQL handles mismatched aggregation levels.</li></ul><p>Make sure to watch the videos about joins, and complete both the MySQL and the Teradata exercises. At the end of the week, you will test your understanding of the SQL syntax introduced this week by completing the Week 3 graded quiz.</p><p>We strongly encourage you to use the course Discussions to help each other with questions. </p> <p>To get started, please begin with the video 'Welcome to Week 3. </p><p>I hope you enjoy this week s materials!</p>"", ""<p>Welcome to week 4, the final week of Managing Big Data with MySQL!  This week you will practice integrating the SQL syntax you ve learn so far into queries that address analysis questions typical of those you will complete as a business data analyst.</p>  <p>By the end of the week, you will be able to:</p><ul><li>Design and execute subqueries</li><li>Introduce logical conditions into your queries using IF and CASE statements</li><li>Implement analyses that accommodate missing data or data mistakes, and</li><li>Write complex queries that incorporate many tables and clauses.</li></ul><p>By the end of this week you will feel confident claiming that you know how to write SQL queries to create business value. Due to the extensive nature of the queries we will practice this week, we have put the graded quiz that tests your understanding of the SQL strategies you will practice in its own week rather than including it in this week s materials. </p> <p>Make sure to complete both the MySQL exercises and the Teradata exercises, and we strongly encourage you to use the course Discussions to help each other with questions.  </p><p>To get started, please begin with the video 'Welcome to Week 4. </p><p>I hope you enjoy this week s materials!</p>"", 'This week contains the final ungraded Teradata exercises, and the final graded quiz for the course. The exercises are intended to hone and build your understanding of the last important concepts in the course, and lead directly to the quiz so be sure to do both!'],)","([],)","(['This course is an introduction to how to use relational databases in business analysis.  You will learn how relational databases work, and how to use entity-relationship diagrams to display the structure of the data held within them.  This knowledge will help you understand how data needs to be collected in business contexts, and help you identify features you want to consider if you are involved in implementing new data collection efforts.  You will also learn how to execute the most useful query and table aggregation statements for business analysts, and practice using them with real databases. No more waiting 48 hours for someone else in the company to provide data to you \xe2\x80\x93 you will be able to get the data by yourself!\n\nBy the end of this course, you will have a clear understanding of how relational databases work, and have a portfolio of queries you can show potential employers. Businesses are collecting increasing amounts of information with the hope that data will yield novel insights into how to improve businesses. Analysts that understand how to access this data \xe2\x80\x93 this means you! \xe2\x80\x93 will have a strong competitive advantage in this data-smitten business world.'],)","(['English'],)","(['Duke University'],)","(['Managing Big Data with MySQL'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/5e/01dd303cf611e5875b7716e9b84653/CourseraIcons.Square1200.4.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Daniel Egger', 'Jana Schaich Borg'],)","(['Week 1 Graded Quiz', 'Week 2 Graded Quiz using Teradata', 'Week 3 Graded Quiz using Teradata', 'Week 5 Graded Quiz using Teradata'],)",https://www.coursera.org/learn/analytics-mysql,"1,560","(['Rated 4.7 out of 5 of ', ' ratings'],)","(['5 weeks, 8-12 hours per week', 'Pass all graded assignments to complete the course.'],)","(['3 videos', ', ', '5 readings', '9 videos', ', ', '8 readings', '8 videos', ', ', '12 readings', '6 videos', ', ', '8 readings', '2 videos', ', ', '7 readings', '1 video', ', ', '4 readings'],)","(['About this Specialization and Course ', 'Understanding Relational Databases', ' Queries to Extract Data from Single Tables ', 'Queries to Summarize Groups of Data from Multiple Tables ', ' Queries to Address More Detailed Business Questions', 'Strengthen and Test Your Understanding '],)"
"([],)","(['Students with interest, but no experience in structured query language (SQL) or database design'],)","([""In this course, you'll walk through installation steps for installing a text editor, installing MAMP or XAMPP (or equivalent) and creating a MySql Database. You'll learn about single table queries and the basic syntax of the SQL language, as well as database design with multiple tables, foreign keys, and the JOIN operation. Lastly, you'll learn to model many-to-many relationships like those needed to represent users, roles, and courses.""],)","(['English'],)","(['University of Michigan'],)","(['Introduction to Structured Query Language (SQL)'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/44/aacce094c211e79257af44295fda12/WA4E_thumbnail_SQL_1x1.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Charles Severance'],)","(['Autograder: Single-table SQL (Users)', 'Peer Grader: Multi-Table Databases (Tracks)', 'Autograder: Many-to-Many Databases'],)",https://www.coursera.org/learn/intro-sql,94,"(['Rated 4.8 out of 5 of ', ' ratings'],)","(['Intermediate', '8-10 hours per week', 'The typical student will use a laptop or desktop computer running MacOX, Windows, or Linux.', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '3 readings', '5 videos', ', ', '1 reading', ', ', '1 practice quiz', '4 videos', ', ', '1 reading', ', ', '1 practice quiz', '1 video', ', ', '1 reading'],)","(['Installing PHP and SQL', 'Introduction to Structured Query Language (SQL)', 'Database Design', 'Many-To-Many'],)"
"([],)","(['This is course is primarily aimed at new Data  Analysts,  Business  Analysts, and Business  Intelligence  professionals. It is also intended for Cloud  Data  Engineers  who  will  be partnering  with  Data  Analysts  to  build scalable  data  solutions  on  Google Cloud  Platform.'],)","(['This is the second course in the Data to Insights specialization. Here we will cover how to ingest new external datasets into BigQuery and  visualize them with Google Data Studio. We will also cover intermediate SQL concepts like multi-table JOINs and UNIONs which will allow you to analyze data across multiple data sources.\n\nNote: Even if you have a background in SQL there are BigQuery specifics (like handling query cache and table wildcards) that may be new to you.'],)","(['English'],)","(['Google Cloud'],)","(['Creating New BigQuery Datasets and Visualizing Insights'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0a/4f9960bd3311e7ac0b715269c3f193/header-2.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Module 6 Quiz', 'Module 7 Quiz', 'Module 8 Quiz', 'Module 9 Quiz'],)",https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,20,"(['Rated 4.2 out of 5 of ', ' ratings'],)","(['Beginner', '1 week of study, 5-7 hours/week', ""You'll need a desktop web browser to run this course's interactive labs via Qwiklabs."", 'Pass all graded assignments to complete the course.'],)","(['6 videos', '4 videos', '7 videos', '7 videos'],)","(['Module 6: Storing and Exporting Data', 'Module 7: Ingesting New Datasets into Google BigQuery', 'Module 8: Data Visualization', 'Module 9: Joining and Merging Datasets'],)"
"(['Welcome to the first module of the Big Data Platform course. This first module will provide insight into Big Data Hype, its technologies opportunities and challenges.  We will take a deeper look into the Hadoop stack and tool and technologies associated with Big Data solutions.  \n', 'In this module we will take a detailed look at the Hadoop Distributed File System (HDFS). We will cover the main design goals of HDFS, understand the read/write process to HDFS, the main configuration parameters that can be tuned to control HDFS performance and robustness, and get an overview of the different ways you can access data on HDFS.', 'This module will introduce Map/Reduce concepts and practice.  You will learn about the big idea of Map/Reduce and you will learn how to design, implement, and execute tasks in the map/reduce framework. You will also learn the trade-offs in map/reduce and how that motivates other tools.', 'Welcome to module 5, Introduction to Spark, this week we will focus on the Apache Spark cluster computing framework, an important contender of Hadoop MapReduce in the Big Data Arena.\n\nSpark provides great performance advantages over Hadoop MapReduce,especially for iterative algorithms, thanks to in-memory caching. Also, gives Data Scientists an easier way to write their analysis pipeline in Python and Scala,even providing interactive shells to play live with data.'],)","([],)","([""This course is for novice programmers or business people who would like to understand the core tools used to wrangle and analyze big data. With no prior experience, you will have the opportunity to walk through hands-on examples with Hadoop and Spark frameworks, two of the most common in the industry. You will be comfortable explaining the specific components and basic processes of the Hadoop architecture, software stack, and execution environment.   In the assignments you will be guided in how data scientists apply the important concepts and techniques such as Map-Reduce that are used to solve fundamental problems in big data.  You'll feel empowered to have conversations about big data and the data analysis process.""],)","(['English'],)","(['University of California, San Diego'],)","(['Hadoop Platform and Application Framework'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/65/8530204d0911e5b1b0bd675d89e7b7/big-data-_2_.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Natasha Balac', 'Paul Rodriguez', 'Andrea Zonca'],)","(['Basic Hadoop Stack', 'Overview of Hadoop Stack', 'Hadoop Execution Environment', 'Hadoop Applications', 'HDFS Architecture', 'HDFS performance,tuning, and robustness', 'Accessing HDFS', 'Running Wordcount with Hadoop streaming, using Python code', 'Lesson 1 Review', 'Joining Data ', 'Spark Lesson 1', 'Spark Lesson 2', 'Simple Join in Spark', 'Spark Lesson 3', 'Advanced Join in Spark'],)",https://www.coursera.org/learn/hadoop,,"([],)","(['5 weeks of study, 1-2 hours/week', 'Pass all graded assignments to complete the course.'],)","(['7 videos', ', ', '4 readings', '10 videos', ', ', '6 readings', '9 videos', ', ', '5 readings', '9 videos', ', ', '3 readings', '10 videos', ', ', '4 readings'],)","(['Hadoop Basics', 'Introduction to the Hadoop Stack', 'Introduction to Hadoop Distributed File System (HDFS)', 'Introduction to Map/Reduce', 'Spark'],)"
"(['Analysis of data starts with a hypothesis and through exploration, those hypothesis are tested.  Exploratory analysis in IoT considers large amounts of data, past or current, from multiple sources and summarizes its main characteristics.  Data is strategically inspected, cleaned, and models are created with the purpose of gaining insight, predicting  future data, and supporting decision making.     This learning module introduces methods for turning raw IoT data into insight ', 'Data analysis for IoT indicates that you have to build a solution for performing scalable analytics, on a large amount of data that arrives in great volumes and velocity.  Such a solution needs to be supported by a number of tools.   This module introduces common and popular tools, and highlights how they help data analyst produce viable end-to-end  solutions. '],)","(['This course is designed for developers who want to improve their data analysis skills or data analysts who want to become expert in finding interesting patterns in IoT Sensor Data. '],)","([""The value of IoT can be found within the analysis of data gathered from the system under observation, where insights gained can have direct impact on business and operational transformation.   Through analysis data correlation, patterns, trends, and other insight are discovered.  Insight leads to better communication between stakeholders, or actionable insights, which can be used to raise alerts or send commands, back to IoT devices.\nWith a focus on the topic of Exploratory Data Analysis, the course provides an in-depth look at mathematical foundations of basic statistical measures, and how they can be used in conjunction with advanced charting libraries to make use of the world\xe2\x80\x99s best pattern recognition system \xe2\x80\x93 the human brain.  Learn how to work with the data, and depict it in ways that support visual inspections, and derive to inferences about the data. Identify interesting characteristics, patterns, trends, deviations or inconsistencies, and potential outliers.  The goal is that you are able to implement end-to-end analytic workflows at scale, from data acquisition to actionable insights. \nThrough a series of lectures and exercises students get the needed skills to perform such analysis on any data, although we clearly focus on IoT Sensor Event Data.\n\nAfter completing this course, you will be able to:\n\xe2\x80\xa2\tDescribe how basic statistical measures, are used to reveal  patterns within the data \n\xe2\x80\xa2\tRecognize data characteristics, patterns, trends, deviations or inconsistencies, and potential outliers.\n\xe2\x80\xa2\tIdentify useful techniques for working with big data such as dimension reduction and feature selection methods \n\xe2\x80\xa2\tUse advanced tools and charting libraries to:\n      o\tAutomatically store data from IoT device(s) \n      o\timprove efficiency of analysis of big-data with partitioning and parallel analysis \n      o\tVisualize the data in an number of 2D and 3D formats (Box Plot, Run Chart, Scatter Plot, Pareto Chart, and Multidimensional Scaling)\n\nFor successful completion of the course, the following prerequisites are recommended: \n\xe2\x80\xa2\tBasic programming skills in any programming language (python preferred)\n\xe2\x80\xa2\tA good grasp of basic algebra and algebraic equations\n\xe2\x80\xa2\t(optional) \xe2\x80\x9cA developer's guide to the Internet of Things (IoT)\xe2\x80\x9d - a Coursera course\n\xe2\x80\xa2\tBasic SQL is a plus\n\nIn order to complete this course, the following technologies will be used:\n(These technologies are introduced in the course as necessary so no previous knowledge is required.)\n\xe2\x80\xa2\tIBM Watson IoT Platform (MQTT Message Broker as a Service, Device Management and Operational Rule Engine)\n\xe2\x80\xa2\tIBM Bluemix (Open Standard Platform Cloud)\n\xe2\x80\xa2\tNode-Red\n\xe2\x80\xa2\tCloudant NoSQL (Apache CouchDB)\n\xe2\x80\xa2\tApacheSpark\n\xe2\x80\xa2\tLanguages: R, Scala and Python (focus on Python)\n\nThis course takes four weeks, 4-6h per week""],)","(['English'],)","(['IBM'],)","([""A developer's guide to Exploring and Visualizing IoT Data""],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/67/10bdb0bb3511e6b53dc54dc0afc009/data_molecules.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Romeo Kienzler'],)","(['Challenges, terminology, methods and technology', 'Week 1 Programming Assignment 1', 'Week 1 Programming Assignment 2', 'Data storage solutions, and ApacheSpark', 'Programming language options and functional programming', 'ApacheSparkSQL, Cloudant, and the End to End Scenario', 'Week 2 Programming Assignment', 'Averages and standard deviation', 'Skewness and kurtosis', 'Covariance, correlation and multidimensional Vector Spaces', 'Programming Assignment 3', 'Visualization and dimension reduction', 'Programming Assignment Week 4'],)",https://www.coursera.org/learn/exploring-visualizing-iot-data,53,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['Beginner', 'Pass all graded assignments to complete the course.'],)","(['5 videos', '9 videos', ', ', '3 readings', '7 videos', ', ', '1 reading', '5 videos', ', ', '2 readings'],)","(['Introduction to exploratory analysis', 'Tools that support IoT solutions', 'Mathematical Foundations on Exploratory Data Analysis', 'Data Visualization'],)"
"([],)","([],)","(['The capstone course, Design and Build a Data Warehouse for Business Intelligence Implementation, features a real-world case study that integrates your learning across all courses in the specialization. In response to business requirements presented in a case study, you\xe2\x80\x99ll design and build a small data warehouse, create data integration workflows to refresh the warehouse, write SQL statements to support analytical and summary query requirements, and use the MicroStrategy business intelligence platform to create dashboards and visualizations.\n\nIn the first part of the capstone course, you\xe2\x80\x99ll be introduced to a medium-sized firm, learning about their data warehouse and business intelligence requirements and existing data sources. You\xe2\x80\x99ll first architect a warehouse schema and dimensional model for a small data warehouse. You\xe2\x80\x99ll then create data integration workflows using Pentaho Data Integration to refresh your data warehouse. Next, you\xe2\x80\x99ll write SQL statements for analytical query requirements and create materialized views to support summary data management. Finally, you will use MicroStrategy OLAP capabilities to gain insights into your data warehouse. In the completed project, you\xe2\x80\x99ll have built a small data warehouse containing a schema design, data integration workflows, analytical queries, materialized views, dashboards and visualizations that you\xe2\x80\x99ll be proud to show to your current and prospective employers.'],)","(['English'],)","(['University of Colorado System'],)","(['Design and Build a Data Warehouse for Business Intelligence Implementation'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/d2/c183504d0911e59bd777c2a1ef6a6e/Course-5---Logo.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Michael Mannino', 'Jahangir Karimi'],)","(['Data warehouse design assignment', 'Assignment for module 3', 'Quiz for module 5 assignment-Production DW', 'Analytical Query Assignment', 'Data Visualization and Dashboard Design Assignment'],)",https://www.coursera.org/learn/data-warehouse-bi-building,163,"(['Rated 4.6 out of 5 of ', ' ratings'],)","(['6 weeks of study, 3-5 hours/week', 'Pass all graded assignments to complete the course.'],)","(['3 videos', ', ', '9 readings', '1 video', ', ', '4 readings', '3 videos', ', ', '5 readings', ', ', '1 practice quiz', '1 video', ', ', '3 readings', '2 videos', ', ', '4 readings', '2 videos', ', ', '1 reading'],)","(['Course Overview', 'Data Warehouse Design', 'Data Integration', 'Analytical Queries and Summary Data Management', ' Data Visualization and Dashboard Design Requirements  ', 'Wrap Up and Project Submission'],)"
"([],)","(['This class is intended for experienced developers who are responsible for managing big data transformations including 1) Extracting, Loading, Transforming, cleaning, and validating data 2) Designing pipelines and architectures for data processing 3) Creating and maintaining machine learning and statistical models 4) Querying datasets, visualizing query results and creating reports'],)","(['This one-week accelerated on-demand course provides participants a a hands-on introduction to designing and building machine learning models on Google Cloud Platform. Through a combination of presentations, demos, and hand-on labs, participants will learn machine learning (ML) and TensorFlow concepts, and develop hands-on skills in developing, evaluating, and productionizing ML models.\n\nOBJECTIVES\n\nThis course teaches participants the following skills:\n\n  \xe2\x97\x8f Identify use cases for machine learning\n\n  \xe2\x97\x8f Build an ML model using TensorFlow\n\n  \xe2\x97\x8f Build scalable, deployable ML models using Cloud ML\n\n  \xe2\x97\x8f Know the importance of preprocessing and combining features\n\n  \xe2\x97\x8f Incorporate advanced ML concepts into their models\n\n  \xe2\x97\x8f Productionize trained ML models\n\n\nPREREQUISITES\n\nTo get the most of out of this course, participants should have:\n\n  \xe2\x97\x8f Completed Google Cloud Fundamentals- Big Data and Machine Learning course OR have equivalent experience\n\n  \xe2\x97\x8f Basic proficiency with common query language such as SQL\n\n  \xe2\x97\x8f Experience with data modeling, extract, transform, load activities\n\n  \xe2\x97\x8f Developing applications using a common programming language such Python\n\n  \xe2\x97\x8f Familiarity with Machine Learning and/or statistics\n\nNotes:\n\xe2\x80\xa2 You\'ll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n\xe2\x80\xa2 There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as ""business"" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n\xe2\x80\xa2 More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/'],)","(['English'],)","(['Google Cloud'],)","(['Serverless Machine Learning with Tensorflow on Google Cloud Platform'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/21/86d4304fa211e7be3013defd1eb386/Serverless_ML_Header.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Graded Quiz #1', 'Graded Quiz #2', 'Graded Quiz #3', 'Graded Quiz #4'],)",https://www.coursera.org/learn/serverless-machine-learning-gcp,314,"(['Rated 4.4 out of 5 of ', ' ratings'],)","(['Intermediate', '1 week of study, 8-12 hours/week', ""You'll need a Google Cloud Platform Free Trial account. Sign up at: https://cloud.google.com/free/"", 'Pass all graded assignments to complete the course.'],)","(['3 videos', ', ', '1 practice quiz', '24 videos', ', ', '1 reading', '14 videos', ', ', '3 readings', '5 videos', ', ', '1 reading', '13 videos', ', ', '1 reading'],)","(['Welcome to Serverless Machine Learning on Google Cloud Platform', 'Module 1: Getting Started with Machine Learning', 'Module 2: Building ML models with Tensorflow', 'Module 3: Scaling ML models with Cloud ML Engine', 'Module 4: Feature Engineering'],)"
"(['In Module 1, we introduce you to the world of Big Data applications. We start by introducing you to Apache Spark, a common framework used for many different tasks throughout the course. We then introduce some Big Data distro packages, the HDFS file system, and finally the idea of batch-based Big Data processing using the MapReduce programming paradigm. ', 'In this module, you will learn about large scale data storage technologies and frameworks. We start by exploring the challenges of storing large data in distributed systems. We then discuss in-memory key/value storage systems, NoSQL distributed databases, and distributed publish/subscribe queues. ', 'In this module, we discuss the applications of Big Data. In particular, we focus on two topics: graph processing, where massive graphs (such as the web graph) are processed for information, and machine learning, where massive amounts of data are used to train models such as clustering algorithms and frequent pattern mining. We also introduce you to deep learning, where large data sets are used to train neural networks with effective results. '],)","(['This course is intended for practitioners. We introduce a wide range of Big Data technologies and frameworks that are very commonly used across computer industry. We assume you are familiar with some programming language (such as Python or Java), and are now interested to take your knowledge to the next step by leveraging ""frameworks"" that do much of the heavy lifting involved in distributed Big Data systems. Most of the code snippets introduced in the lectures can be read as pseudocode. '],)","(['Welcome to the Cloud Computing Applications course, the second part of a two-course series designed to give you a comprehensive view on the world of Cloud Computing and Big Data!\n\nIn this second course we continue Cloud Computing Applications by exploring how the Cloud opens up data analytics of huge volumes of data that are static or streamed at high velocity and represent an enormous variety of information. Cloud applications and data analytics represent a disruptive change in the ways that society is informed by, and uses information. We start the first week by introducing some major systems for data analysis including Spark and the major frameworks and distributions of analytics applications including Hortonworks, Cloudera, and MapR. By the middle of week one we introduce the HDFS distributed and robust file system that is used in many applications like Hadoop and finish week one by exploring the powerful MapReduce programming model and how distributed operating systems like YARN and Mesos support a flexible and scalable environment for Big Data analytics. In week two, our course introduces large scale data storage and the difficulties and problems of consensus in enormous stores that use quantities of processors, memories and disks. We discuss eventual consistency, ACID, and BASE and the consensus algorithms used in data centers including Paxos and Zookeeper. Our course presents Distributed Key-Value Stores and in memory databases like Redis used in data centers for performance. Next we present NOSQL Databases. We visit HBase, the scalable, low latency database that supports database operations in applications that use Hadoop. Then again we show how Spark SQL can program SQL queries on huge data. We finish up week two with a presentation on Distributed Publish/Subscribe systems using Kafka, a distributed log messaging system that is finding wide use in connecting Big Data and streaming applications together to form complex systems. Week three moves to fast data real-time streaming and introduces Storm technology that is used widely in industries such as Yahoo. We continue with Spark Streaming, Lambda and Kappa architectures, and a presentation of the Streaming Ecosystem. Week four focuses on Graph Processing, Machine Learning, and Deep Learning. We introduce the ideas of graph processing and present Pregel, Giraph, and Spark GraphX. Then we move to machine learning with examples from Mahout and Spark. Kmeans, Naive Bayes, and fpm are given as examples. Spark ML and Mllib continue the theme of programmability and application construction. The last topic we cover in week four introduces Deep Learning technologies including Theano, Tensor Flow, CNTK, MXnet, and Caffe on Spark.'],)","(['English'],)","(['University of Illinois at Urbana-Champaign'],)","(['Cloud Computing Applications, Part 2: Big Data and Applications in the Cloud'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/d3/1c09b01d2e11e69fcf2d6c6ce4d4b6/cloud_applications_part-2.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Reza Farivar', 'Roy H. Campbell'],)","(['Module 1 Quiz', 'Module 2 Quiz', 'Module 3 Quiz', 'Module 4 Quiz'],)",https://www.coursera.org/learn/cloud-applications-part2,97,"(['Rated 4 out of 5 of ', ' ratings'],)","([""There is about 3-4 hours of video lectures per week. Each week's quiz takes about 30 minutes. "", 'Pass all graded assignments to complete the course.'],)","(['1 video', ', ', '4 readings', ', ', '1 practice quiz', '13 videos', ', ', '1 reading', '22 videos', ', ', '1 reading', '18 videos', ', ', '1 reading', '18 videos', ', ', '1 reading'],)","(['Course Orientation', 'Module 1: Spark, Hortonworks, HDFS, CAP', 'Module 2: Large Scale Data Storage', 'Module 3: Streaming Systems', 'Module 4: Graph Processing and Machine Learning'],)"
"([],)","(['This course is aimed to everybody, who feel interest in Big Data. As the technologies covered throughout the course operate in Unix environment, we expect you to have basic understanding of the subject. Things like processes and files assumed to be familiar for the learner. Python is required to complete programming assignments. To get the most out of this course, you need to know Hadoop and Hive. You should also have a working knowledge of Spark, Spark SQL and Python.'],)","(['There is a significant number of tasks when we need not just to process an enormous volume of data but to process it as quickly as possible. Delays in tsunami prediction can cost people\xe2\x80\x99s lives. Delays in traffic jam prediction cost extra time. Advertisements based on the recent users\xe2\x80\x99 activity are ten times more popular.\n\nHowever, stream processing techniques alone are not enough to create a complete real-time system. For example to create a recommendation system we need to have a storage that allows to store and fetch data for a user with minimal latency. These databases should be able to store hundreds of terabytes of data, handle billions of requests per day and have a 100% uptime. NoSQL databases are commonly used to solve this challenging problem.\n\nAfter you finish this course, you will master stream processing systems and NoSQL databases. You will also learn how to use such popular and powerful systems as  Kafka, Cassandra and Redis.\n\nTo get the most out of this course, you need to know Hadoop and Hive. You should also have a working knowledge of Spark, Spark SQL and Python.\n\nDo you want to learn how to build Big Data applications that can withstand modern challenges? Jump right in!'],)","(['English'],)","(['Yandex'],)","(['Big Data Applications: Real-Time Streaming'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/6c/3ed810a14611e78aa07dc9a47a1790/Yandex-466_4.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Ivan Puzyrevskiy', 'Pavel Mezentsev ', 'Emeli Dral ', 'Alexey A. Dral'],)","([],)",https://www.coursera.org/learn/real-time-streaming-big-data,,"([],)","(['Advanced', '4 weeks of study, 6-8 hours/week', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","(['This class is intended for data analysts and data scientists responsible for: analyzing and visualizing big data, implementing cloud-based big data solutions, deploying or migrating big data applications to the public cloud, implementing and maintaining large-scale data storage environments, and transforming/processing big data.'],)","(['This 1-week, accelerated on-demand course builds upon Google Cloud Platform Big Data and Machine Learning Fundamentals. Through a combination of instructor-led presentations, demonstrations, and hands-on labs, students learn how to carry out no-ops data warehousing, analysis and pipeline processing.\n\nPrerequisites:\n\xe2\x80\xa2 Google Cloud Platform Big Data and Machine Learning Fundamentals\n\xe2\x80\xa2 Experience using a SQL-like query language to analyze data\n\xe2\x80\xa2 Knowledge of either Python or Java\n\nNotes:\n\xe2\x80\xa2 You\'ll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n\xe2\x80\xa2 There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as ""business"" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n\xe2\x80\xa2 More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/'],)","(['English'],)","(['Google Cloud'],)","(['Serverless Data Analysis with Google BigQuery and Cloud Dataflow'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/2f/11eaf0593d11e7bbf6470fbff8981f/Big-Data.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Module 1 Quiz', 'Module 2 Quiz'],)",https://www.coursera.org/learn/serverless-data-analysis-bigquery-cloud-dataflow-gcp,310,"(['Rated 4.5 out of 5 of ', ' ratings'],)","(['Intermediate', '1 week of study, 6-8 hours/week', ""You'll need a Google Cloud Platform Free Trial account. Sign up at: https://cloud.google.com/free/"", 'Pass all graded assignments to complete the course.'],)","(['3 videos', '17 videos', ', ', '3 readings', '19 videos', ', ', '4 readings'],)","(['Welcome to Serverless Data Analysis with Google BigQuery and Cloud Dataflow', 'Module 1: Serverless Data Analysis with BigQuery', 'Module 2: Autoscaling Data Processing Pipelines with Dataflow'],)"
"([],)","(['This class is intended for Data analysts, Data scientists and Business analysts. It is also suitable for IT decision makers evaluating Google Cloud Platform for use by data scientists.\n\nThis class is for people who do the following with big data:\n\n\xe2\x80\xa2 Extracting, Loading, Transforming, cleaning, and validating data for use in analytics\n\xe2\x80\xa2 Designing pipelines and architectures for data processing\n\xe2\x80\xa2 Creating and maintaining machine learning and statistical models\n\xe2\x80\xa2 Querying datasets, visualizing query results and creating reports'],)","(['This 1-week accelerated on-demand course introduces participants to the Big Data and Machine Learning capabilities of Google Cloud Platform (GCP). It provides a quick overview of the Google Cloud Platform and a deeper dive of the data processing capabilities.\n\nAt the end of this course, participants will be able to:\n\xe2\x80\xa2 Identify the purpose and value of the key Big Data and Machine Learning products in the Google Cloud Platform\n\xe2\x80\xa2 Use CloudSQL and Cloud Dataproc to migrate existing MySQL and Hadoop/Pig/Spark/Hive workloads to Google Cloud Platform\n\xe2\x80\xa2 Employ BigQuery and Cloud Datalab to carry out interactive data analysis\n\xe2\x80\xa2 Choose between Cloud SQL, BigTable and Datastore\n\xe2\x80\xa2 Train and use a neural network using TensorFlow\n\xe2\x80\xa2 Choose between different data processing products on the Google Cloud Platform\n\nBefore enrolling in this course, participants should have roughly one (1) year of experience with one or more of the following:\n\xe2\x80\xa2 A common query language such as SQL\n\xe2\x80\xa2 Extract, transform, load activities\n\xe2\x80\xa2 Data modeling\n\xe2\x80\xa2 Machine learning and/or statistics\n\xe2\x80\xa2 Programming in Python\n\nGoogle Account Notes:\n\xe2\x80\xa2 You\'ll need a Google/Gmail account and a credit card or bank account to sign up for the Google Cloud Platform free trial (Google is currently blocked in China).\n\xe2\x80\xa2 There is a known issue with certain EU countries where individuals are not able to sign up, but you may sign up as ""business"" status and intend to see a potential economic benefit from the trial. More details at: https://support.google.com/cloud/answer/6090602\n\xe2\x80\xa2 More Google Cloud Platform free trial FAQs are available at: https://cloud.google.com/free-trial/'],)","(['English'],)","(['Google Cloud'],)","(['Google Cloud Platform Big Data and Machine Learning Fundamentals'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0d/dfca001e4b11e7b3efcf607d794a33/BD-and-ML-Fundamentals-Header.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Module 1 Review', 'Module 2 Review', 'Module 3 Review', 'Module 4 Review', 'Module 5 Review'],)",https://www.coursera.org/learn/gcp-big-data-ml-fundamentals,"1,115","(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Intermediate', '1 week of study, 6-10 hours/week', ""You'll need a Google Cloud Platform Free Trial account. Sign up at: https://cloud.google.com/free/"", 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '1 reading', '6 videos', ', ', '1 reading', '9 videos', ', ', '3 readings', '10 videos', ', ', '2 readings', '13 videos', ', ', '4 readings', '4 videos', ', ', '1 reading', '3 videos', ', ', '1 reading'],)","(['Introduction to the Data and Machine Learning on Google Cloud Platform Specialization', 'Module 1: Introduction to Google Cloud Platform and its Big Data Products', 'Module 2: Foundations of GCP Compute and Storage', 'Module 3: Data Analysis on the Cloud', 'Module 4: Scaling Data Analysis: Compute with GCP', 'Module 5: Data Processing Architectures: Scalable Ingest, Transform and Load', 'Module 6: Summary of Google Cloud Platform, Big Data, and ML'],)"
"([],)","([],)","(['Are you ready to close the loop on your Big Data skills? Do you want to apply all your knowledge you got from the previous courses in practice? Finally, in the Capstone project, you will integrate all the knowledge acquired earlier to build a real application leveraging the power of Big Data.\n\nYou will be given a task to combine data from different sources of different types (static distributed dataset, streaming data, SQL or NoSQL storage). Combined, this data will be used to build a predictive model for a financial market (as an example). First, you design a system from scratch and share it with your peers to get valuable feedback. Second, you can make it public, so get ready to receive the feedback from your service users. Real-world experience without any 3G-glasses or mock interviews.'],)","(['English'],)","(['Yandex'],)","(['Big Data Services: Capstone Project'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/84/6873b0a14611e7a43d47ca6b50b400/Yandex-466_5.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Alexey A. Dral', 'Ivan Puzyrevskiy'],)","([],)",https://www.coursera.org/learn/big-data-services,,"([],)","(['Advanced', 'Pass all graded assignments to complete the course.'],)","([],)","([],)"
"([],)","([],)","(['This course we will explore the foundations of software security. We will consider important software vulnerabilities and attacks that exploit them -- such as buffer overflows, SQL injection, and session hijacking -- and we will consider defenses that prevent or mitigate these attacks, including advanced testing and program analysis techniques. Importantly, we take a ""build security in"" mentality, considering techniques at each phase of the development cycle that can be used to strengthen the security of software systems. Successful learners in this course typically have completed sophomore/junior-level undergraduate work in a technical field, have some familiarity with programming, ideally in C/C++ and one other ""managed"" program language (like ML or Java), and have prior exposure to algorithms. Students not familiar with these languages but with others can improve their skills through online web tutorials.'],)","(['English'],)","(['University of Maryland, College Park'],)","(['Software Security '],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/14/abbf60e67c11e391bedd928f66fcc0/CYBER_hicks.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Michael Hicks'],)","(['Week 1 quiz', 'VM BOF quiz', 'Week 2 quiz', 'BadStore quiz', 'Week 3 quiz', 'Week 4 quiz', 'Project 3 quiz', 'Week 5 quiz', 'Week 6 quiz'],)",https://www.coursera.org/learn/software-security,517,"(['Rated 4.6 out of 5 of ', ' ratings'],)","(['6 weeks of study, 3-5 hours/week', 'Pass all graded assignments to complete the course.'],)","(['3 videos', ', ', '4 readings', ', ', '1 practice quiz', '6 videos', ', ', '2 readings', '7 videos', ', ', '1 reading', '10 videos', ', ', '2 readings', '10 videos', ', ', '1 reading', '13 videos', ', ', '2 readings', '5 videos', ', ', '1 reading'],)","(['OVERVIEW', 'LOW-LEVEL SECURITY', 'DEFENDING AGAINST LOW-LEVEL EXPLOITS', 'WEB SECURITY', 'SECURE SOFTWARE DEVELOPMENT', 'PROGRAM ANALYSIS', 'PEN TESTING'],)"
"([],)","(['Students who would like to learn to build database-backed web applications'],)","([""In this course, we'll look at the object oriented patterns available in PHP. You'll learn how to connect to a MySQL using the Portable Data Objects (PDO) library and issue SQL commands in the the PHP language. We'll also look at how PHP uses cookies and manages session data. You'll learn how PHP avoids double posting data, how flash messages are implemented, and how to use a session to log in users in web applications. We'll then build the first 'complete' application that has multiple screens to Create, Read, Update and Delete (CRUD) our data. This brings all the previous concepts together and will form the basis for all later web applications.""],)","(['English'],)","(['University of Michigan'],)","(['Building Database Applications in PHP'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/5f/534b3094c211e783d43998c65a97c8/WA4E_thumbnail_PHP2_1x1.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Charles Severance'],)","(['Autograder: Autos Database', 'Peer graded: Autos Database', 'Auto-Grader: Cookies and Session', 'Auto-Grader: Autos with Post-Redirect', 'Peer-Grader: Autos with Post-Redirect', 'Auto-Grader: Autos CRUD', 'Peer-Grader: Autos CRUD'],)",https://www.coursera.org/learn/database-applications-php,24,"(['Rated 4.9 out of 5 of ', ' ratings'],)","(['Intermediate', '8-10 hours per week', 'The typical student will use a laptop or desktop computer running MacOX, Windows, or Linux. ', 'Pass all graded assignments to complete the course.'],)","(['6 videos', ', ', '1 reading', ', ', '1 practice quiz', '8 videos', ', ', '1 reading', ', ', '1 practice quiz', '4 videos', ', ', '1 practice quiz', '6 videos', ', ', '1 reading', ', ', '1 practice quiz', '2 videos', ', ', '1 reading'],)","(['PHP Objects', 'Connecting PHP and MySQL', 'PHP Cookies and Sessions', 'PHP Redirect, Routing, and Authentication', 'Building a CRUD Application'],)"
"([' In this module we will learn how to hack web app with command injection vulnerability with only four characters malicious string.    We will learn how to hack web app with database backend with SQL injection vulnerability and potentially show the list of passwords by injecting string to overwrite SQL query. We will learn how to perform code review to spot the key statements/their patterns that expose the programs for such injection attacks and learn how to patch them.  We will learn how to apply security design pattern to defend injection attacks and enhance web security.  ', 'In this module we will learn how to hack web app with database backend with SQL injection vulnerability and potentially show the list of passwords by injecting string to overwrite SQL query.We will learn how to perform code review to spot the key statements/their patterns that expose the programs for such injection attacks and learn how to patch them. We will learn the eight-step hacker methodology for exploit systems. For the escalating privilege techniques, we show how to leverage command injection vulnerability to search file systems and deposit/hide Trojans for future exploit.\n', 'In this module we will learn how to perform Vulnerability Scanning with Nessus tool, \nlearn to perform penetration testing using tools included in  Kali Linux distribution and to use Metasploit Framework to take control a vulnerable machine, deploy keylogger, run remote shell and remote VNC injection.  \n'],)","(['Any one interested in learning how to hack and patch web apps with injection vulnerabilities, crack passwords on AWS P2 system, system security design pattern  using hand-on labs, quick introduction to buffer overflow, Nessus scanning tool and Kali Penetration Testing suite.  The needs to know how to program in a high level programming language.'],)","(['In this MOOC, you will learn how to hack web apps with command injection vulnerabilities in a web site of your AWS Linux instance.   You will learn how to search valuable information on a typical Linux systems with LAMP services, and deposit and hide Trojans for future exploitation.  You will learn how to patch these web apps with input validation using regular expression. You will learn a security design pattern to avoid introducing injection vulnerabilities by input validation and replacing generic system calls with specific function calls.  You will learn how to hack web apps with SQL injection vulnerabilities and retrieve user profile information and passwords.  You will learn how to patch them with input validation and SQL parameter binding.  You will learn the hacking methodology, Nessus tool for scanning vulnerabilities, Kali Linux for penetration testing, and Metasploit Framework for gaining access to vulnerable Windows Systems, deploying keylogger, and perform Remote VNC server injection.  You will learn security in memory systems and virtual memory layout, and understand buffer overflow attacks and their defenses.  You will learn how to clone a Kali instance with AWS P2 GPU support and perform hashcat password cracking using dictionary attacks and known pattern mask attacks.'],)","(['English'],)","(['University of Colorado System'],)","(['Hacking and Patching'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/2b/e53710967d11e787cb7bca68fffa6a/uclionChow_editV2.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Edward Chow'],)","(['Project 3a  Hacking Web Apps with Command Injections and Patching them', 'Exam 3.1. Assessing Injection Web App Attacks and Their Defenses', 'Project 3b.  SQL Injection Attacks and Defenses', 'Exam 3.2. Assessing SQL Injection and Hacking Methodology', 'Exam 3.3. Assessing Buffer Overflow Attacks and Defenses', 'Project 3c. Cracking Linux password with hashcat using  AWS P2 GPU.', 'Exam 3.4.  Assessing the Scanning and Penetration Testing Skills'],)",https://www.coursera.org/learn/hacking-patching,4,"(['Rated 5 out of 5 of ', ' ratings'],)","(['Intermediate', 'Pass all graded assignments to complete the course.'],)","(['4 videos', ', ', '2 readings', '6 videos', ', ', '5 readings', '4 videos', ', ', '2 readings', '6 videos', ', ', '3 readings'],)","(['Injection Web App Attacks and Their Defenses', 'Hack SQL Databases and Patch Web Apps with SQL Injection Vulnerabilities', 'Memory Attacks and Defenses', 'Penetration Testing'],)"
"(['In this module, we will begin exploring the database-interaction portion of Rails. We will start off with migrations that enable you to create and modify the schema of the database. We will then move on to discussing the Active Record gem Rails uses, which enables you to create, retrieve, update, and delete the data from the database. Before looking at Active Record, we will talk about some advanced Ruby features of meta-programming that will help facilitate our Active Record journey.', 'In this module, we will continue exploring Active Record and look at ways to code advanced queries without exposing ourselves to risk from SQL injection (as well as what SQL injection actually is). We will then look at expressing relationships between entities in Active Record and validating the data being saved to the database.', 'In this module, we will talk about how to deal with nested resources in Rails. We will then talk about securing your app with a username and password combination for authentication purposes and making sure that users are only authorized to make changes to and view their own resources. We will finish off the module by discussing pagination and deploying to Heroku Paas (Platform as a Service).'],)","([],)","(['You already know how to build a basic web application with the Ruby on Rails framework. Perhaps, you have even taken Course 1, ""Ruby on Rails: An Introduction"" (we highly recommend it) where you relied on external web services to be your \xe2\x80\x9cdata layer\xe2\x80\x9d. But in the back of your mind, you always knew that there would come a time when you would need to roll up your sleeves and learn SQL to be able to interact with your own relational database (RDBMS). But there is an easier way to get started with SQL using the Active Record Object/Relational (ORM) framework. In this course, we will be able to use the Ruby language and the Active Record ORM framework to automate interactions with the database to quickly build the application we want.\n \nIn Rails with Active Record and Action Pack, we will explore how to interact with relational databases by using Active Record, a Ruby gem, which Rails uses by default for database access. We will then take a look at what role Active Record plays in the overall request-response cycle, when a client (the browser) requests data from the server, as well as how to submit the data to the server.  Of course, when accessing data, security is of paramount importance! We will talk about vulnerabilities such as SQL injection, as well as how to secure access to data by authenticating and authorizing users accessing the data. Take this course to build a Ruby on Rails application with Active Record to automate the detailed SQL interactions with our database.'],)","(['English'],)","(['Johns Hopkins University'],)","(['Rails with Active Record and Action Pack'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/ba/f3d3e03bb111e5b9f2a356939796cb/jhep-coursera-course2.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Kalman Hazins'],)","(['Basic Active Record CRUD', 'Active Record Relationships', 'ActionPack', 'Nested Resources, Security, and Pagination'],)",https://www.coursera.org/learn/rails-with-active-record,615,"(['Rated 4.7 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['12 videos', ', ', '3 readings', ', ', '2 practice quizzes', '11 videos', ', ', '2 readings', ', ', '2 practice quizzes', '10 videos', ', ', '2 readings', ', ', '2 practice quizzes', '10 videos', ', ', '2 readings', ', ', '2 practice quizzes'],)","(['Introduction to Active Record', 'Deep Dive into Active Record', 'Introduction to Action Pack', 'Security and Nested Resources in Action Pack'],)"
"(['Module 1 introduces the course and covers concepts that provide a context for the remainder of this course. In the first two lessons, you ll understand the objectives for the course and know what topics and assignments to expect. In the remaining lessons, you will learn about DBMS extensions, a review of schema patterns, data warehouses used in practice problems and assignments, and examples of data warehouses in education and health care. This informational module will ensure that you have the background for success in later modules that emphasize details and hands-on skills.You should also read about the software requirements in the lesson at the end of module 1. I recommend that you try to install the Oracle software this week before assignments begin in week 2. If you have taken other courses in the specialization, you may already have installed the Oracle software.', 'Now that you have the informational context for relational database support of data warehouses, you ll start using relational databases to write business intelligence queries! In module 2, you will learn an important extension of the SQL SELECT statement for subtotal operators. You ll apply what you ve learned in practice and graded problems using Oracle SQL for problems involving the CUBE, ROLLUP, and GROUPING SETS operators. Because the subtotal operators are part of the SQL standard, your learning will readily apply to other enterprise DBMSs. At the end of this module, you will have solid background to write queries using the SQL subtotal operators as a data warehouse analyst.', 'After your experience using the SQL subtotal operators, you are ready to learn another important SQL extension for business intelligence applications. In module 3, you will learn about an extended processing model for SQL analytic functions that support common analysis in business intelligence applications. You ll apply what you ve learned in practice and graded problems using Oracle SQL for problems involving qualitative ranking of business units, window comparisons showing relationships of business units over time, and quantitative contributions showing performance thresholds and contributions of individual business units to a whole business. Because analytic functions are part of the SQL standard, your learning will apply to other enterprise DBMSs. At the end of this module, you will have solid background to write queries using the SQL analytic functions as a data warehouse analyst.', 'After acquiring query formulation skills for development of business intelligence applications, you are ready to learn about DBMS extensions for efficient query execution. Business intelligence queries can use lots of resources so materialized view processing and design has become an important extension of DBMSs. In module 4, you will learn about an SQL statement for creating materialized views, processing requirements for materialized views, and rules for rewriting queries using materialized views. To gain insight about the complexity of query rewriting, you will practice rewriting queries using materialized views. To provide closure about relational database support for data warehouses, you will learn about about Oracle tools for data integration, the Oracle Data Integrator, along with two SQL statements useful for specific data integration tasks. After this module, you will have a solid background to use materialized views to improve query performance and deploy the Extraction, Loading, and Transformation approach for data integration as a data warehouse administrator or analyst.', 'Module 5 finishes the course with a return to conceptual material about physical design technologies and data governance practices. You will learn about storage architectures, scalable parallel processing, big data issues, and data governance. After this module, you will have background about conceptual issues important for data warehouse administrators.'],)","([],)","([""Relational Database Support for Data Warehouses is the third course in the Data Warehousing for Business Intelligence specialization. In this course, you'll use analytical elements of SQL for answering business intelligence questions. You'll learn features of relational database management systems for managing summary data commonly used in business intelligence reporting. Because of the importance and difficulty of managing implementations of data warehouses, we'll also delve into storage architectures, scalable parallel processing, data governance, and big data impacts.""],)","(['English'],)","(['University of Colorado System'],)","(['Relational Database Support for Data Warehouses'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/0a/6522804d0a11e59bd777c2a1ef6a6e/Course-3---Logo.png?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Michael Mannino'],)","(['Module 1 quiz', 'Module 2 quiz', 'Quiz for module 2 assignment', 'Assignment for module 2', 'Module 3 quiz', 'Quiz for module 3 assignment', 'Assignment for module 3', 'Module 4 quiz', 'Quiz for module 4 assignment', 'Assignment for module 4', 'Module 5 quiz'],)",https://www.coursera.org/learn/dwrelational,366,"(['Rated 4.6 out of 5 of ', ' ratings'],)","(['Pass all graded assignments to complete the course.'],)","(['7 videos', ', ', '14 readings', '5 videos', ', ', '12 readings', '5 videos', ', ', '12 readings', '5 videos', ', ', '11 readings', '5 videos', ', ', '5 readings'],)","(['DBMS Extensions and Example Data Warehouses', 'SQL Subtotal Operators', 'SQL Analytic Functions', 'Materialized View Processing and Design', 'Physical Design and Governance'],)"
"([],)","(['This training is primarily for software developers, system administrators, and IT professionals who are focused on Microsoft Windows.'],)","(['Learn to deploy and run Microsoft Windows\xc2\xae applications on Google Cloud Platform (GCP). Through lectures and hands-on labs, learn how to configure and run Microsoft Windows and Microsoft SQL Server in Google Compute Engine. You will also learn how to develop and deploy ASP.NET applications and deploy them to Google Compute Engine, Google App Engine, and Google Container Engine.\n\nCourse objectives\nThis course teaches participants the following skills:\n\xe2\x80\xa2 Configuring Microsoft Windows and Microsoft SQL Server in Google Compute Engine\n\xe2\x80\xa2 Deploying ASP.NET MVC applications to Google Compute Engine\n\xe2\x80\xa2 Deploying .NET Core applications to Google Compute Engine, Google Compute Engine, and Google Container Engine\n\nPre-requisites\n\xe2\x80\xa2 System-administration or application-development experience with Microsoft Windows\n\xe2\x80\xa2 A general familiarity with cloud computing'],)","(['English'],)","(['Google Cloud'],)","(['Develop and Deploy Windows Applications on Google Cloud Platform'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/8d/4b2df08d1a11e7ae469fce720331be/GCP-for-AWS-Pros.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Introduction to Google Cloud', 'Windows Workloads on Google Cloud Platform', 'Developing ASP.NET MVC Applications', 'Configuring Resilient Workloads', 'Introducing ASP.NET Core on GCP', 'ASP.NET Core and Google Container Engine', 'ASP.NET Core and Google App Engine'],)",https://www.coursera.org/learn/develop-windows-apps-gcp,2,"(['Rated 5 out of 5 of ', ' ratings'],)","(['Beginner', '1 week of study, 6-8 hours/week', ""You'll need a desktop web browser to run this course's interactive labs via Qwiklabs."", 'Pass all graded assignments to complete the course.'],)","(['2 videos', '4 videos', '2 videos', '2 videos', '3 videos'],)","(['Module 1: Introduction to Google Cloud Platform', 'Module 2: Windows Workloads on Google Compute Engine', 'Module 3: Developing ASP.NET MVC applications ', 'Module 4: Configuring Resilient Workloads ', 'Module 5: Delivering Next-Generation ASP.NET Core on GCP '],)"
"([],)","(['This is course is primarily aimed at new Data  Analysts,  Business  Analysts, and Business  Intelligence  professionals. It is also intended for Cloud  Data  Engineers  who  will  be partnering  with  Data  Analysts  to  build scalable  data  solutions  on  Google Cloud  Platform.'],)","(['The third course in this specialization is Achieving Advanced Insights with BigQuery. Here we will build on your growing knowledge of SQL as we dive into advanced functions and how to break apart a complex query into manageable steps. \n\nWe will cover the internal architecture of BigQuery (column-based sharded storage) and advanced SQL topics like nested and repeated fields through the use of Arrays and Structs. Lastly we will dive into optimizing your queries for performance and how you can secure your data through authorized views.'],)","(['English'],)","(['Google Cloud'],)","(['Achieving Advanced Insights with BigQuery'],)",https://d3njjcbhbojbot.cloudfront.net/api/utilities/v1/imageproxy/https://coursera-course-photos.s3.amazonaws.com/26/4fc5c0c02311e794566563069ec6ca/header-2.jpg?auto=format%2Ccompress&dpr=2&exp=-10&blur=10&bri=5&max-w=1000,"(['Google Cloud Training'],)","(['Advanced Functions', 'BigQuery Architecture', 'Advanced Google Data Studio', 'Performance Optimization', 'Cloud Datalab', 'Data Access'],)",https://www.coursera.org/learn/gcp-advanced-insights-bigquery,12,"(['Rated 4.8 out of 5 of ', ' ratings'],)","(['Beginner', '1 week of study, 5-7 hours/week', ""You'll need a desktop web browser to run this course's interactive labs via Qwiklabs."", 'Pass all graded assignments to complete the course.'],)","(['6 videos', '8 videos', '2 videos', '5 videos', '3 videos', '1 video', '1 video'],)","(['Module 10: Advanced Functions and Clauses', 'Module 11: Schema Design and Nested Data Structures', 'Module 12: More Visualization with Google Data Studio', 'Module 13: Optimizing for Performance', 'Module 14: Advanced Insights with Cloud Datalab', 'Module 15: Data Access', 'Completion'],)"
